{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import heapq\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data_from_file(file_name):\n",
    "    '''\n",
    "    Arguments:\n",
    "    file_name -- the json file name saving results.\n",
    "\n",
    "    Returns:\n",
    "    data -- json serializable data.\n",
    "    '''    \n",
    "    with open(file_name, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    return data\n",
    "\n",
    "def load_embedding_from_file(file_name):\n",
    "    '''\n",
    "    Arguments:\n",
    "    file_name -- the json file name saving results.\n",
    "\n",
    "    Returns:\n",
    "    embeddings -- numpy array\n",
    "    '''\n",
    "    with open(file_name, 'r') as f:\n",
    "        embeddings = np.array(json.loads(\"\".join(f.readlines())))\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word2idx_map = load_data_from_file('weights/word2idx_map')\n",
    "idx2word_map = load_data_from_file('weights/idx2word_map')\n",
    "embeddings = load_embedding_from_file('weights/test/epoch2.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Arithmetics\n",
    "\n",
    "### - Sigmoid Function\n",
    "$$\\sigma(x) = \\frac{1}{1 + e^{-x}} \\tag{1}$$\n",
    "$$\\sigma'(x) = \\sigma(x) * (1 - \\sigma(x)) \\tag{2}$$\n",
    "\n",
    "### - Hyperbolic Tangent Function\n",
    "$$\\tanh(x) = \\frac{e^{2x} - 1}{e^{2x} + 1} \\tag{3}$$\n",
    "$$\\tanh'(x) = 1 - \\tanh^{2}(x) \\tag{4}$$\n",
    "\n",
    "### - Softmax Function\n",
    "$$ softmax(x_i) = \\frac{e^{x_i}}{\\sum_{i} e^{x_i}} \\tag{5}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def init_parameters(n_x, n_a, n_y):\n",
    "    '''\n",
    "    Implements the xavier initialization of LSTM parameters.\n",
    "    \n",
    "    Arguments:\n",
    "    n_x -- dimension of input, int\n",
    "    n_a -- dimension of state, int\n",
    "    n_y -- dimension of output, int\n",
    "\n",
    "    Returns:\n",
    "    parameters -- dictionary of parameters\n",
    "    \n",
    "    '''\n",
    "    parameters = {}\n",
    "\n",
    "    for gate in ['f', 'i', 'c', 'o']:\n",
    "        Wx = np.random.randn(n_a, n_x) / np.sqrt(n_x)\n",
    "        Wa = np.random.randn(n_a, n_a) / np.sqrt(n_a)\n",
    "        parameters['W' + gate] = np.concatenate([Wx, Wa], axis=-1)\n",
    "        parameters['b' + gate] = np.zeros((n_a, 1))\n",
    "        \n",
    "    parameters['Wy'] = np.random.randn(n_y, n_a) / np.sqrt(n_a)\n",
    "    parameters['by'] = np.zeros((n_y, 1))\n",
    "\n",
    "    return parameters\n",
    "\n",
    "def sigmoid(logits):\n",
    "    return 1 / (1 + np.exp(-logits))\n",
    "\n",
    "def sigmoid_derivative(s):\n",
    "    return s * (1 - s)\n",
    "\n",
    "def tanh_derivative(t):\n",
    "    return 1 - np.power(t, 2)\n",
    "\n",
    "def softmax(x):\n",
    "    e_x = np.exp(x - np.max(x))\n",
    "    return e_x / e_x.sum(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM Forward Propagation\n",
    "\n",
    "### - Forget Gate\n",
    "$$\\Gamma_f^{\\langle t \\rangle} = \\sigma(W_f \\begin{bmatrix}a^{\\langle t-1 \\rangle}\\\\ x^{\\langle t \\rangle}\\end{bmatrix} + b_f)\\tag{6} $$\n",
    "\n",
    "### - Ignore Gate\n",
    "$$\\Gamma_i^{\\langle t \\rangle} = \\sigma(W_i \\begin{bmatrix}a^{\\langle t-1 \\rangle}\\\\ x^{\\langle t \\rangle}\\end{bmatrix} + b_i)\\tag{7} $$\n",
    "\n",
    "### - Update Gate\n",
    "$$\\widetilde{c}^{\\langle t \\rangle} = tanh(W_c \\begin{bmatrix}a^{\\langle t-1 \\rangle}\\\\ x^{\\langle t \\rangle}\\end{bmatrix} + b_c)\\tag{8} $$\n",
    "\n",
    "### - Output Gate\n",
    "$$\\Gamma_o^{\\langle t \\rangle} = \\sigma(W_o \\begin{bmatrix}a^{\\langle t-1 \\rangle}\\\\ x^{\\langle t \\rangle}\\end{bmatrix} + b_o)\\tag{9} $$\n",
    "\n",
    "### - Next Cell's State\n",
    "$$c^{\\langle t \\rangle} = \\Gamma_f^{\\langle t \\rangle}\\circ c^{\\langle t-1 \\rangle} + \\Gamma_i^{\\langle t \\rangle}\\circ \\widetilde{c}^{\\langle t \\rangle}\\tag{10}$$\n",
    "$$a^{\\langle t \\rangle} = \\Gamma_o^{\\langle t \\rangle} \\circ tanh(c^{\\langle t \\rangle})\\tag{11}$$\n",
    "\n",
    "### - Output Layer\n",
    "$$\\widehat{y}^{\\langle t \\rangle} = softmax(W_y a^{\\langle t \\rangle} + b_y)\\tag{12}$$\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cell_forward(xt, a_prev, c_prev, parameters):\n",
    "    '''\n",
    "    Calculate the single forward step of LSTM-cell.\n",
    "    \n",
    "    Arguments:\n",
    "    xt -- input data at time step t, numpy array of shape (n_x, m)\n",
    "    a_prev -- numpy array of shape (n_a, m)\n",
    "    c_prev -- numpy array of shape (n_a, m)\n",
    "    \n",
    "    Returns:\n",
    "    a_next -- numpy array of shape (n_a, m)\n",
    "    c_next -- numpy array of shape (n_a, m)\n",
    "    y_pred_t -- numpy array of shape (n_y, m)\n",
    "    cache -- tuple contains variable needed for backprop\n",
    "    \n",
    "    '''\n",
    "    Wf = parameters['Wf']\n",
    "    bf = parameters['bf']\n",
    "    Wi = parameters['Wi']\n",
    "    bi = parameters['bi']\n",
    "    Wc = parameters['Wc']\n",
    "    bc = parameters['bc']\n",
    "    Wo = parameters['Wo']\n",
    "    bo = parameters['bo']\n",
    "    Wy = parameters['Wy']\n",
    "    by = parameters['by']\n",
    "    \n",
    "    concat = np.vstack([xt, a_prev])\n",
    "    ft = sigmoid(np.dot(Wf, concat) + bf)\n",
    "    it = sigmoid(np.dot(Wi, concat) + bi)\n",
    "    ct = np.tanh(np.dot(Wc, concat) + bc)\n",
    "    ot = sigmoid(np.dot(Wo, concat) + bo)\n",
    "    c_next = ft * c_prev + it * ct\n",
    "    a_next = ot * np.tanh(c_next)\n",
    "    \n",
    "    y_pred_t = softmax(np.dot(Wy, a_next) + by)\n",
    "\n",
    "    cache = (xt, a_prev, c_prev, c_next, ft, it, ct, ot)\n",
    "\n",
    "    return a_next, c_next, y_pred_t, cache\n",
    "\n",
    "def forward_propagation(x, a0, c0, parameters):\n",
    "    '''\n",
    "    Calculate the forward propagation for whole time steps.\n",
    "    \n",
    "    Arguments:\n",
    "    x -- input word vectors, numpy array of shape (n_x, m, T)\n",
    "    a0 -- initial hidden state, numpy array of shape (n_a, m)\n",
    "    c0 -- initial memory state, numpy array of shape (n_a, m)\n",
    "    \n",
    "    Returns:\n",
    "    y_pred -- numpy array of shape (n_y, m, T)\n",
    "    a -- numpy array of shape (n_a, m, T)\n",
    "    caches -- list of cache\n",
    "    \n",
    "    '''\n",
    "    n_x, m, T = x.shape\n",
    "    n_y, n_a = parameters['Wy'].shape\n",
    "    \n",
    "    y_pred = np.zeros((n_y, m, T))\n",
    "    a = np.zeros((n_a, m, T))\n",
    "    at = a0\n",
    "    ct = c0\n",
    "    caches = []\n",
    "\n",
    "    for t in range(T):\n",
    "        at, ct, y_pred_t, cache = cell_forward(x[:, :, t], at, ct, parameters)\n",
    "        caches.append(cache)\n",
    "        a[:, :, t] = at\n",
    "        y_pred[:, :, t] = y_pred_t\n",
    "\n",
    "    return y_pred, a, caches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss Function of Classification\n",
    "\n",
    "$$ \\mathcal{L}^{(i)\\langle t \\rangle} = - \\sum_{k = 0}^{n_y - 1} y^{(i)}_k \\cdot log(\\widehat{y}^{(i)}_k) \\tag{13}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_loss(y_pred, y):\n",
    "    '''\n",
    "    Arguments:\n",
    "    y_pred -- numpy array of shape (n_y, m, T)\n",
    "    y -- numpy array of shape (m, T)\n",
    "    \n",
    "    Returns:\n",
    "    loss: float\n",
    "    '''\n",
    "    loss = -np.mean(np.log(y_pred)[y, :, :])\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM Backward Propagation\n",
    "\n",
    "\n",
    "### - Output Layer's Derivative\n",
    "$$da^{\\langle t \\rangle} = W_y^{T}(\\widehat{y}^{\\langle t \\rangle} - y^{\\langle t \\rangle}) \\tag{14}$$\n",
    "$$dW_y = \\sum_{t = 0}^{T - 1} (\\widehat{y}^{\\langle t \\rangle} - y^{\\langle t \\rangle}) a^{\\langle t \\rangle T} \\tag{15}$$\n",
    "$$db_y = \\sum_{t = 0}^{T - 1} \\sum_{i = 0}^{m - 1} (\\widehat{y}^{(i)\\langle t \\rangle} - y^{(i)\\langle t \\rangle})\\tag{16}$$\n",
    "\n",
    "### - Gates' Derivative\n",
    "$$d\\Gamma_f^{\\langle t \\rangle} = da^{\\langle t \\rangle} \\circ tanh(c^{\\langle t \\rangle})\\tag{17}$$\n",
    "$$d\\widetilde c^{\\langle t \\rangle} = (dc^{\\langle t \\rangle} + da^{\\langle t \\rangle} \\circ \\Gamma_o^{\\langle t \\rangle}\\circ tanh'(c^{\\langle t \\rangle})) \\circ \\Gamma_i^{\\langle t \\rangle}\\tag{18}$$\n",
    "$$d\\Gamma_i^{\\langle t \\rangle} = (dc^{\\langle t \\rangle} + da^{\\langle t \\rangle} \\circ \\Gamma_o^{\\langle t \\rangle}\\circ tanh'(c^{\\langle t \\rangle})) \\circ \\widetilde c^{\\langle t \\rangle}\\tag{19}$$\n",
    "$$d\\Gamma_f^{\\langle t \\rangle} = (dc^{\\langle t \\rangle} + da^{\\langle t \\rangle} \\circ \\Gamma_o^{\\langle t \\rangle}\\circ tanh'(c^{\\langle t \\rangle})) \\circ c^{\\langle t-1 \\rangle}\\tag{20}$$\n",
    "\n",
    "### - Parameters' Derivative\n",
    "$$dZ_f^{\\langle t\\rangle} = d\\Gamma_f^{\\langle t \\rangle} \\circ \\sigma'(Z_f^{\\langle t \\rangle}) \\tag{21}$$\n",
    "$$dZ_i^{\\langle t\\rangle} = d\\Gamma_i^{\\langle t \\rangle} \\circ \\sigma'(Z_i^{\\langle t \\rangle}) \\tag{22}$$\n",
    "$$dZ_c^{\\langle t\\rangle} = d\\widetilde c^{\\langle t \\rangle} \\circ tanh'(Z_c^{\\langle t \\rangle}) \\tag{23}$$\n",
    "$$dZ_o^{\\langle t\\rangle} = d\\Gamma_o^{\\langle t \\rangle} \\circ \\sigma'(Z_o^{\\langle t \\rangle}) \\tag{24}$$\n",
    "\n",
    "$$dW_f = \\sum_{t = 0}^{T - 1} dZ_f^{\\langle t\\rangle} \\begin{bmatrix}a^{\\langle t-1 \\rangle}\\\\ x^{\\langle t \\rangle}\\end{bmatrix}^T \\tag{25}$$\n",
    "$$dW_i = \\sum_{t = 0}^{T - 1} dZ_i^{\\langle t\\rangle} \\begin{bmatrix}a^{\\langle t-1 \\rangle}\\\\ x^{\\langle t \\rangle}\\end{bmatrix}^T \\tag{26}$$\n",
    "$$dW_c = \\sum_{t = 0}^{T - 1} dZ_c^{\\langle t\\rangle} \\begin{bmatrix}a^{\\langle t-1 \\rangle}\\\\ x^{\\langle t \\rangle}\\end{bmatrix}^T \\tag{27}$$\n",
    "$$dW_o = \\sum_{t = 0}^{T - 1} dZ_o^{\\langle t\\rangle} \\begin{bmatrix}a^{\\langle t-1 \\rangle}\\\\ x^{\\langle t \\rangle}\\end{bmatrix}^T \\tag{28}$$\n",
    "$$db_f = \\sum_{t = 0}^{T - 1} \\sum_{i = 0}^{m - 1} dZ_f^{(i)\\langle t \\rangle} \\tag{29}$$\n",
    "$$db_i = \\sum_{t = 0}^{T - 1} \\sum_{i = 0}^{m - 1} dZ_i^{(i)\\langle t \\rangle} \\tag{30}$$\n",
    "$$db_c = \\sum_{t = 0}^{T - 1} \\sum_{i = 0}^{m - 1} dZ_c^{(i)\\langle t \\rangle} \\tag{31}$$\n",
    "$$db_o = \\sum_{t = 0}^{T - 1} \\sum_{i = 0}^{m - 1} dZ_o^{(i)\\langle t \\rangle} \\tag{32}$$\n",
    "\n",
    "### - Previous Cell States' Derivative\n",
    "$$\\begin{bmatrix}da^{\\langle t-1 \\rangle}\\\\ dx^{\\langle t \\rangle}\\end{bmatrix} = W_f^T dZ_f^{\\langle t \\rangle} + W_i^T dZ_i^{\\langle t \\rangle} + W_c^T dZ_c^{\\langle t \\rangle} + W_o^T dZ_o^{\\langle t \\rangle} \\tag{33}$$\n",
    "$$dc^{\\langle t-1 \\rangle} = (dc^{\\langle t \\rangle} + da^{\\langle t \\rangle} \\circ \\Gamma_o^{\\langle t \\rangle}\\circ tanh'(c^{\\langle t \\rangle})) \\circ \\Gamma_f^{\\langle t \\rangle} \\tag{34}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def backward_cell(da_next, dc_next, cache, parameters):\n",
    "    '''\n",
    "    Calculate the gradients of parameters in a single LSTM-cell.\n",
    "    \n",
    "    Arguments:\n",
    "    da_next -- derivative of loss to next hidden state, numpy array of shape (n_a, m)\n",
    "    dc_next -- derivative of loss to next memory state, numpy array of shape (n_a, m)\n",
    "    cache -- tuple\n",
    "    parameters -- dictionary\n",
    "    \n",
    "    Returns:\n",
    "    grads: dictionary\n",
    "    '''\n",
    "    xt, a_prev, c_prev, c_next, ft, it, ct, ot = cache\n",
    "    n_a = a_prev.shape[0]\n",
    "    \n",
    "    # Equations (17) ~ (20)\n",
    "    dc_next = dc_next + da_next * ot * tanh_derivative(np.tanh(c_next))\n",
    "    dot = da_next * np.tanh(c_next)\n",
    "    dct = dc_next * it\n",
    "    dit = dc_next * ct\n",
    "    dft = dc_next * c_prev\n",
    "    \n",
    "    # Equations (21) ~ (24)\n",
    "    dZf = dft * sigmoid_derivative(ft)\n",
    "    dZi = dit * sigmoid_derivative(it)\n",
    "    dZo = dot * sigmoid_derivative(ot)\n",
    "    dZc = dct * tanh_derivative(ct)\n",
    "    \n",
    "    # Equations (25) ~ (32)\n",
    "    concat = np.vstack([xt, a_prev])\n",
    "    dWf = np.dot(dZf, concat.T)\n",
    "    dWi = np.dot(dZi, concat.T)\n",
    "    dWo = np.dot(dZo, concat.T)\n",
    "    dWc = np.dot(dZc, concat.T)\n",
    "    dbf = np.sum(dZf, axis=-1, keepdims=True)\n",
    "    dbi = np.sum(dZi, axis=-1, keepdims=True)\n",
    "    dbc = np.sum(dZc, axis=-1, keepdims=True)\n",
    "    dbo = np.sum(dZo, axis=-1, keepdims=True)\n",
    "    \n",
    "    # Equations (33), (34)\n",
    "    Wf, Wi, Wc, Wo = parameters['Wf'], parameters['Wi'], parameters['Wc'], parameters['Wo']\n",
    "    da_prev = (np.dot(Wf.T, dZf) + np.dot(Wi.T, dZi) + np.dot(Wc.T, dZc) + np.dot(Wo.T, dZo))[: n_a, :]\n",
    "    dc_prev = dc_next * ft\n",
    "    \n",
    "    grads = {'a_prev': da_prev, 'c_prev': dc_prev,\n",
    "             'Wf': dWf, 'Wi': dWi, 'Wo': dWo, 'Wc': dWc,\n",
    "             'bf': dbf, 'bi': dbi, 'bo': dbo, 'bc': dbc}\n",
    "    \n",
    "    return grads\n",
    "\n",
    "def convert_to_one_hot(y, n_y):\n",
    "    '''\n",
    "    Arguments:\n",
    "    y -- numpy array of shape (m, T)\n",
    "    n_y -- int\n",
    "    \n",
    "    Returns:\n",
    "    y -- numpy array of shape (n_y, m, T)\n",
    "    '''\n",
    "    y = np.eye(n_y)[:, y]\n",
    "    return y\n",
    "\n",
    "def backward_propagation(y, y_pred, a, caches, parameters):\n",
    "    '''\n",
    "    Calculate the gradients through the backward propagation for whole time steps.\n",
    "    \n",
    "    Arguments:\n",
    "    y -- numpy array of shape (m, T)\n",
    "    y_pred -- numpy array of shape (n_y, m, T)\n",
    "    a -- numpy array of shape (n_a, m, T)\n",
    "    caches -- list\n",
    "    parameters -- dictionary\n",
    "    \n",
    "    Returns:\n",
    "    grads -- dictionary\n",
    "    \n",
    "    '''\n",
    "    x0 = caches[0][0]\n",
    "    n_a, m, T = a.shape\n",
    "    n_x = x0.shape[0]\n",
    "    n_y = y_pred.shape[0]\n",
    "    \n",
    "    dWf = np.zeros((n_a, n_x + n_a))\n",
    "    dWi = np.zeros((n_a, n_x + n_a))\n",
    "    dWc = np.zeros((n_a, n_x + n_a))\n",
    "    dWo = np.zeros((n_a, n_x + n_a))\n",
    "    dbf = np.zeros((n_a, 1))\n",
    "    dbi = np.zeros((n_a, 1))\n",
    "    dbc = np.zeros((n_a, 1))\n",
    "    dbo = np.zeros((n_a, 1))\n",
    "    da_prev = np.zeros((n_a, m))\n",
    "    dc_prev = np.zeros((n_a, m))\n",
    "    \n",
    "    y_oh = convert_to_one_hot(y, n_y)\n",
    "    \n",
    "    # Equations (14) ~ (16)\n",
    "    da = np.tensordot(parameters['Wy'].T, y_pred - y_oh, axes=1)\n",
    "    dWy = np.tensordot(y_pred - y_oh, a, axes=([1, 2], [1, 2]))\n",
    "    dby = np.sum(y_pred - y_oh, axis=(1, 2)).reshape(-1, 1)\n",
    "    \n",
    "    for t in reversed(range(T)):\n",
    "        grad = backward_cell(da[:, :, t] + da_prev, dc_prev, caches[t], parameters)\n",
    "        dWf += grad['Wf']\n",
    "        dWi += grad['Wi']\n",
    "        dWc += grad['Wc']\n",
    "        dWo += grad['Wo']\n",
    "        dbf += grad['bf']\n",
    "        dbi += grad['bi']\n",
    "        dbc += grad['bc']\n",
    "        dbo += grad['bo']\n",
    "        da_prev = grad['a_prev']\n",
    "        dc_prev = grad['c_prev']\n",
    "    \n",
    "    grads = {'Wf': dWf, 'Wi': dWi, 'Wo': dWo, 'Wc': dWc, 'Wy': dWy,\n",
    "             'bf': dbf, 'bi': dbi, 'bo': dbo, 'bc': dbc, 'by': dby}\n",
    "    \n",
    "    return grads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizer\n",
    "\n",
    "$$g_t = \\nabla_\\theta \\mathcal{L}(\\theta_{t-1}) \\tag{35}$$\n",
    "\n",
    "- ### Gradient Descent\n",
    "$$\\theta_t = \\theta_{t - 1} - \\alpha g_t  \\tag{36}$$\n",
    "\n",
    "- ### Adam\n",
    "reference: https://arxiv.org/pdf/1412.6980v8.pdf\n",
    "$$m_t = \\beta_1 m_{t-1} + (1 - \\beta_1) g_t \\tag{37}$$\n",
    "$$v_t = \\beta_2 v_{t-1} + (1 - \\beta_2) g_t^2 \\tag{38}$$\n",
    "$$\\widehat{m}_t = \\frac{m_t}{1 - \\beta_1^{t}} \\tag{39}$$\n",
    "$$\\widehat{v}_t = \\frac{v_t}{1 - \\beta_2^{t}} \\tag{40}$$\n",
    "$$\\theta_t = \\theta_{t-1} - \\alpha \\frac{\\widehat{m}_t}{\\sqrt{\\widehat{v}_t} + \\epsilon} \\tag{41}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Optimizer:\n",
    "    def update(self, parameters, grads):\n",
    "        raise NotImplementedError\n",
    "\n",
    "class GradientDescentOptimzer(Optimizer):\n",
    "    def __init__(self, alpha):\n",
    "        self.alpha = alpha\n",
    "        \n",
    "    def update(self, parameters, grads):\n",
    "        for key in parameters.keys():\n",
    "            parameters[key] -= self.alpha * grads[key]\n",
    "            \n",
    "class Adam(Optimizer):\n",
    "    def __init__(self, alpha, parameters, beta1=0.9, beta2=0.999, epsilon=1e-8, decay=0.):\n",
    "        self.m = {}\n",
    "        self.v = {}\n",
    "        self.alpha = alpha\n",
    "        self.beta1 = beta1\n",
    "        self.beta2 = beta2\n",
    "        self.epsilon = epsilon\n",
    "        self.decay = decay\n",
    "        self.t = 1\n",
    "        \n",
    "        for key, param in parameters.items():\n",
    "            self.m[key] = np.zeros_like(param)\n",
    "            self.v[key] = np.zeros_like(param)\n",
    "        \n",
    "    def update(self, parameters, grads):\n",
    "        '''\n",
    "        Arguments:\n",
    "        parameters -- dictionary\n",
    "        grads -- dictionary\n",
    "        '''\n",
    "        \n",
    "        lr = self.alpha * (np.sqrt(1. - np.power(self.beta2, self.t)) /\n",
    "                           (1. - np.power(self.beta1, self.t)))\n",
    "        if self.decay > 0:\n",
    "            lr /= 1 + self.decay * (self.t - 1)\n",
    "        for key in parameters.keys():\n",
    "            self.m[key] = self.beta1 * self.m[key] + (1. - self.beta1) * grads[key]\n",
    "            self.v[key] = self.beta2 * self.v[key] + (1. - self.beta2) * np.square(grads[key])\n",
    "            parameters[key] -= lr * self.m[key] / (np.sqrt(self.v[key]) + self.epsilon)\n",
    "\n",
    "        self.t += 1\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_n_lines(file, n):\n",
    "    '''\n",
    "    A generator that read multiple lines from file stream.\n",
    "    \n",
    "    Arguments:\n",
    "    file -- a reading file stream\n",
    "    n -- int\n",
    "    \n",
    "    Yields:\n",
    "    lines -- list of line\n",
    "    '''\n",
    "    while True:\n",
    "        lines = [file.readline().decode(\"utf-8\").strip() for _ in range(n)]\n",
    "        if lines[-1]:\n",
    "            yield lines\n",
    "        else:\n",
    "            return\n",
    "\n",
    "def generate_batch(lines, word2idx_map, embeddings, T):\n",
    "    '''\n",
    "    Arguments:\n",
    "    sentence -- \n",
    "    word2idx_map -- dictionary\n",
    "    word2vec_map -- dictionary\n",
    "    T -- int\n",
    "    \n",
    "    Returns:\n",
    "    x -- numpy array of shape (n_x, m, T)\n",
    "    y -- numpy array of shape (m, T)\n",
    "    '''\n",
    "    n_x, n_y = embeddings.shape\n",
    "    m = len(lines)\n",
    "    \n",
    "    x_batch = np.zeros((n_x, m, T + 1))\n",
    "    y_batch = np.zeros((m, T), dtype=int)\n",
    "    \n",
    "    for i, line in enumerate(lines):\n",
    "        words = line.split()\n",
    "        t = 0\n",
    "        for w in words:\n",
    "            idx = word2idx_map.get(w, -1)\n",
    "            if idx == -1:\n",
    "                continue\n",
    "            x_batch[:, i, t + 1] = embeddings[:, idx]\n",
    "            y_batch[i, t] = idx\n",
    "            t += 1\n",
    "    \n",
    "    return x_batch[:, :, :T], y_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model(file_name, word2idx_map, embeddings, length,\n",
    "          batch_size=64, lstm_unit=64, n_epochs=2, learning_rate=0.001, optimizer='adam'):\n",
    "    '''\n",
    "    Arguments:\n",
    "    file_name -- string\n",
    "    word2idx_map -- corresponding row indices of words, dictionary\n",
    "    embeddings -- embedding vectors of input words, numpy array of shape (embed_size, n_vocab)\n",
    "    max_length -- the length of sentences, int\n",
    "    batch_size -- size of mini-batch, int\n",
    "    lstm_unit -- dimension of states, int\n",
    "    n_epochs -- int\n",
    "    learning_rate -- float\n",
    "    optimizer -- string\n",
    "    \n",
    "    Returns:\n",
    "    parameters -- dictionary\n",
    "    \n",
    "    '''\n",
    "    n_x, n_y = embeddings.shape\n",
    "    n_a = lstm_unit\n",
    "    parameters = init_parameters(n_x, n_a, n_y)\n",
    "    \n",
    "    if optimizer == 'gd':\n",
    "        optimizer = GradientDescentOptimzer(learning_rate)\n",
    "    elif optimizer == 'adam':\n",
    "        optimizer = Adam(learning_rate, parameters)\n",
    "    \n",
    "    a0 = np.zeros((n_a, batch_size))\n",
    "    c0 = np.zeros((n_a, batch_size))\n",
    "    \n",
    "    avg_loss = 0.\n",
    "    count = 0\n",
    "    trained_words = 0\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        with open(file_name, 'rb') as f:\n",
    "            for lines in read_n_lines(f, batch_size):\n",
    "                x_batch, y_batch = generate_batch(lines, word2idx_map, embeddings, length)\n",
    "                y_pred, a_batch, caches = forward_propagation(x_batch, a0, c0, parameters)\n",
    "                \n",
    "                loss = compute_loss(y_pred, y_batch)\n",
    "                trained_words += batch_size * length\n",
    "                \n",
    "                avg_loss += loss\n",
    "                count += 1\n",
    "                \n",
    "                if count == 10:\n",
    "                    print('Trained words: %s, Loss: %.4f'% (trained_words, avg_loss / count))\n",
    "                    sen, _, _ = generate_poem(parameters, idx2word_map, embeddings, length=length)\n",
    "                    print(sen)\n",
    "                    avg_loss = 0.\n",
    "                    count = 0\n",
    "                    \n",
    "                grads = backward_propagation(y_batch, y_pred, a_batch, caches, parameters)\n",
    "                optimizer.update(parameters, grads)\n",
    "                \n",
    "    return parameters      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained words: 3200, Loss: 8.6054\n",
      "來俟簀八嚀\n",
      "Trained words: 6400, Loss: 8.5760\n",
      "雲陽韻服下\n",
      "Trained words: 9600, Loss: 8.5399\n",
      "自萬薨悲至\n",
      "Trained words: 12800, Loss: 8.4830\n",
      "功外身春昌\n",
      "Trained words: 16000, Loss: 8.3629\n",
      "千四對明歌\n",
      "Trained words: 19200, Loss: 8.1889\n",
      "金氣明聲雲\n",
      "Trained words: 22400, Loss: 7.9879\n",
      "中水聲望歸\n",
      "Trained words: 25600, Loss: 7.8251\n",
      "金時驚生花\n",
      "Trained words: 28800, Loss: 7.7507\n",
      "春去春長開\n",
      "Trained words: 32000, Loss: 7.6968\n",
      "歌天月來春\n",
      "Trained words: 35200, Loss: 7.6937\n",
      "道落去中去\n",
      "Trained words: 38400, Loss: 7.6265\n",
      "玉花一月陽\n",
      "Trained words: 41600, Loss: 7.6603\n",
      "人為一春人\n",
      "Trained words: 44800, Loss: 7.4598\n",
      "為路不雲不\n",
      "Trained words: 48000, Loss: 7.4273\n",
      "不下月色中\n",
      "Trained words: 51200, Loss: 7.3392\n",
      "一山心相不\n",
      "Trained words: 54400, Loss: 7.5642\n",
      "得如君雲日\n",
      "Trained words: 57600, Loss: 7.6877\n",
      "行水不中君\n",
      "Trained words: 60800, Loss: 7.6797\n",
      "為天明歸門\n",
      "Trained words: 64000, Loss: 7.6532\n",
      "清花明月落\n",
      "Trained words: 67200, Loss: 7.4860\n",
      "遠飛人天長\n",
      "Trained words: 70400, Loss: 7.4477\n",
      "何不秋未何\n",
      "Trained words: 73600, Loss: 7.4080\n",
      "流山城雲雲\n",
      "Trained words: 76800, Loss: 7.5979\n",
      "人相臨夜月\n",
      "Trained words: 80000, Loss: 7.6158\n",
      "月有三飛水\n",
      "Trained words: 83200, Loss: 7.5634\n",
      "三下人山有\n",
      "Trained words: 86400, Loss: 7.2952\n",
      "開在山不複\n",
      "Trained words: 89600, Loss: 7.4559\n",
      "花在人春秋\n",
      "Trained words: 92800, Loss: 7.4211\n",
      "雲下林月月\n",
      "Trained words: 96000, Loss: 7.5849\n",
      "日朝來鳥所\n",
      "Trained words: 99200, Loss: 7.3343\n",
      "如流此不何\n",
      "Trained words: 102400, Loss: 7.4553\n",
      "望月心相天\n",
      "Trained words: 105600, Loss: 7.3786\n",
      "入生天歸風\n",
      "Trained words: 108800, Loss: 7.3095\n",
      "中林海花江\n",
      "Trained words: 112000, Loss: 7.3212\n",
      "玉海遠北山\n",
      "Trained words: 115200, Loss: 7.4248\n",
      "天歸日山來\n",
      "Trained words: 118400, Loss: 7.4535\n",
      "望林空金初\n",
      "Trained words: 121600, Loss: 7.4734\n",
      "無中三山風\n",
      "Trained words: 124800, Loss: 7.4654\n",
      "此路歸金長\n",
      "Trained words: 128000, Loss: 7.3640\n",
      "臨春出年有\n",
      "Trained words: 131200, Loss: 7.4159\n",
      "無入開光知\n",
      "Trained words: 134400, Loss: 7.5605\n",
      "水開方春開\n",
      "Trained words: 137600, Loss: 7.3197\n",
      "山入上時歌\n",
      "Trained words: 140800, Loss: 7.3147\n",
      "玉影花下葉\n",
      "Trained words: 144000, Loss: 7.3555\n",
      "有林秋知光\n",
      "Trained words: 147200, Loss: 7.3214\n",
      "北水開望何\n",
      "Trained words: 150400, Loss: 7.3915\n",
      "春山秋白三\n",
      "Trained words: 153600, Loss: 7.2568\n",
      "金行城上花\n",
      "Trained words: 156800, Loss: 7.4179\n",
      "明下望此三\n",
      "Trained words: 160000, Loss: 7.2059\n",
      "金自君月歸\n",
      "Trained words: 163200, Loss: 7.3241\n",
      "不山山年為\n",
      "Trained words: 166400, Loss: 7.2709\n",
      "月林華一時\n",
      "Trained words: 169600, Loss: 7.3799\n",
      "飛日中一人\n",
      "Trained words: 172800, Loss: 7.3784\n",
      "望日心日長\n",
      "Trained words: 176000, Loss: 7.3940\n",
      "事天君無相\n",
      "Trained words: 179200, Loss: 7.4123\n",
      "風明流空流\n",
      "Trained words: 182400, Loss: 7.4308\n",
      "入山心長明\n",
      "Trained words: 185600, Loss: 7.3329\n",
      "秋雲將春陽\n",
      "Trained words: 188800, Loss: 7.3522\n",
      "玉天人天去\n",
      "Trained words: 192000, Loss: 7.3646\n",
      "入高子無中\n",
      "Trained words: 195200, Loss: 7.3429\n",
      "光何秋生夜\n",
      "Trained words: 198400, Loss: 7.3224\n",
      "為出無秋來\n",
      "Trained words: 201600, Loss: 7.2061\n",
      "開朝日風露\n",
      "Trained words: 204800, Loss: 7.2595\n",
      "三風水金林\n",
      "Trained words: 208000, Loss: 7.2322\n",
      "南日入人上\n",
      "Trained words: 211200, Loss: 7.3259\n",
      "雲下一相未\n",
      "Trained words: 214400, Loss: 7.3091\n",
      "出花入入歸\n",
      "Trained words: 217600, Loss: 7.1947\n",
      "風聞聞客生\n",
      "Trained words: 220800, Loss: 7.2389\n",
      "言複歸何客\n",
      "Trained words: 224000, Loss: 7.1586\n",
      "言行複為行\n",
      "Trained words: 227200, Loss: 7.1529\n",
      "來花月聲色\n",
      "Trained words: 230400, Loss: 7.2763\n",
      "門朝白衣空\n",
      "Trained words: 233600, Loss: 7.2357\n",
      "朝一裏一向\n",
      "Trained words: 236800, Loss: 7.1538\n",
      "出複雲生不\n",
      "Trained words: 240000, Loss: 7.2699\n",
      "朝門上山去\n",
      "Trained words: 243200, Loss: 7.5343\n",
      "清中空春寒\n",
      "Trained words: 246400, Loss: 7.3710\n",
      "高此時時多\n",
      "Trained words: 249600, Loss: 7.0017\n",
      "此言人日無\n",
      "Trained words: 252800, Loss: 7.2764\n",
      "道君時日風\n",
      "Trained words: 256000, Loss: 7.1694\n",
      "自日入雲人\n",
      "Trained words: 259200, Loss: 7.2500\n",
      "林中日歸山\n",
      "Trained words: 262400, Loss: 7.0588\n",
      "空見無何一\n",
      "Trained words: 265600, Loss: 6.8587\n",
      "知言方歸見\n",
      "Trained words: 268800, Loss: 6.9335\n",
      "此在東山水\n",
      "Trained words: 272000, Loss: 7.0110\n",
      "天心上林處\n",
      "Trained words: 275200, Loss: 6.9303\n",
      "人年行天水\n",
      "Trained words: 278400, Loss: 7.1894\n",
      "雲陽夜風春\n",
      "Trained words: 281600, Loss: 7.3431\n",
      "風舟明江白\n",
      "Trained words: 284800, Loss: 7.4265\n",
      "暮望事何事\n",
      "Trained words: 288000, Loss: 7.1883\n",
      "長獨事日去\n",
      "Trained words: 291200, Loss: 7.3388\n",
      "長暮心何知\n",
      "Trained words: 294400, Loss: 7.1690\n",
      "中天萬里白\n",
      "Trained words: 297600, Loss: 7.2186\n",
      "時自春上裏\n",
      "Trained words: 300800, Loss: 7.2973\n",
      "無江生望雲\n",
      "Trained words: 304000, Loss: 7.3089\n",
      "相雲中落江\n",
      "Trained words: 307200, Loss: 7.2398\n",
      "不能我日子\n",
      "Trained words: 310400, Loss: 7.2016\n",
      "自聞無來流\n",
      "Trained words: 313600, Loss: 7.2295\n",
      "青風花天風\n",
      "Trained words: 316800, Loss: 7.2457\n",
      "江山萬人去\n",
      "Trained words: 320000, Loss: 7.2997\n",
      "心得所此在\n",
      "Trained words: 323200, Loss: 7.1258\n",
      "無知人君天\n",
      "Trained words: 326400, Loss: 7.1337\n",
      "自為無不有\n",
      "Trained words: 329600, Loss: 7.1926\n",
      "江山雲飛滿\n",
      "Trained words: 332800, Loss: 7.0518\n",
      "風雲無時陽\n",
      "Trained words: 336000, Loss: 7.1526\n",
      "青雲見江中\n",
      "Trained words: 339200, Loss: 7.0445\n",
      "何青去天山\n",
      "Trained words: 342400, Loss: 7.1555\n",
      "風白山月風\n",
      "Trained words: 345600, Loss: 6.9922\n",
      "山雲出雲入\n",
      "Trained words: 348800, Loss: 7.0757\n",
      "朝月落相山\n",
      "Trained words: 352000, Loss: 7.0387\n",
      "雲高一白雲\n",
      "Trained words: 355200, Loss: 7.2456\n",
      "雲何天山天\n",
      "Trained words: 358400, Loss: 7.3793\n",
      "秋色飛長落\n",
      "Trained words: 361600, Loss: 7.2423\n",
      "江長不道王\n",
      "Trained words: 364800, Loss: 7.2179\n",
      "海然人來可\n",
      "Trained words: 368000, Loss: 7.2913\n",
      "天人山秋雲\n",
      "Trained words: 371200, Loss: 7.3180\n",
      "君山此為方\n",
      "Trained words: 374400, Loss: 7.1968\n",
      "忽出海草見\n",
      "Trained words: 377600, Loss: 7.2559\n",
      "秋春何山人\n",
      "Trained words: 380800, Loss: 7.2301\n",
      "今人亦未非\n",
      "Trained words: 384000, Loss: 7.2638\n",
      "朝門方不方\n",
      "Trained words: 387200, Loss: 7.2911\n",
      "不心生不同\n",
      "Trained words: 390400, Loss: 7.3094\n",
      "行此時相未\n",
      "Trained words: 393600, Loss: 7.1908\n",
      "一方為此無\n",
      "Trained words: 396800, Loss: 7.1439\n",
      "此與西日海\n",
      "Trained words: 400000, Loss: 7.1841\n",
      "自日出樓水\n",
      "Trained words: 403200, Loss: 7.1633\n",
      "有知與事如\n",
      "Trained words: 406400, Loss: 7.2492\n",
      "上流秋雲新\n",
      "Trained words: 409600, Loss: 7.1706\n",
      "何年與自歸\n",
      "Trained words: 412800, Loss: 7.2790\n",
      "相知不從子\n",
      "Trained words: 416000, Loss: 7.3860\n",
      "長南水門遠\n",
      "Trained words: 419200, Loss: 7.3459\n",
      "日空有高生\n",
      "Trained words: 422400, Loss: 7.1005\n",
      "山上上門門\n",
      "Trained words: 425600, Loss: 7.4635\n",
      "多今知去難\n",
      "Trained words: 428800, Loss: 7.6057\n",
      "無知別未未\n",
      "Trained words: 432000, Loss: 7.5906\n",
      "雲向不已如\n",
      "Trained words: 435200, Loss: 7.5039\n",
      "明長多意見\n",
      "Trained words: 438400, Loss: 7.3876\n",
      "東不得知能\n",
      "Trained words: 441600, Loss: 7.4632\n",
      "萬不不無有\n",
      "Trained words: 444800, Loss: 7.4820\n",
      "清出關人未\n",
      "Trained words: 448000, Loss: 7.5548\n",
      "君人知所久\n",
      "Trained words: 451200, Loss: 7.6233\n",
      "上萬何得不\n",
      "Trained words: 454400, Loss: 7.6664\n",
      "知得中山雲\n",
      "Trained words: 457600, Loss: 7.5077\n",
      "有不當方公\n",
      "Trained words: 460800, Loss: 7.6400\n",
      "日見人無自\n",
      "Trained words: 464000, Loss: 7.5318\n",
      "空一相我難\n",
      "Trained words: 467200, Loss: 7.4552\n",
      "君見風地相\n",
      "Trained words: 470400, Loss: 7.3177\n",
      "見山南春秋\n",
      "Trained words: 473600, Loss: 7.3281\n",
      "自從有時開\n",
      "Trained words: 476800, Loss: 7.2121\n",
      "有門青清路\n",
      "Trained words: 480000, Loss: 7.2493\n",
      "遠何何不如\n",
      "Trained words: 483200, Loss: 7.3085\n",
      "今山道自一\n",
      "Trained words: 486400, Loss: 7.4829\n",
      "客相知無盡\n",
      "Trained words: 489600, Loss: 7.4274\n",
      "青天東白石\n",
      "Trained words: 492800, Loss: 7.2573\n",
      "雲秋氣露不\n",
      "Trained words: 496000, Loss: 7.4043\n",
      "春風深山頭\n",
      "Trained words: 499200, Loss: 7.4818\n",
      "空林日不白\n",
      "Trained words: 502400, Loss: 7.4448\n",
      "子君得行自\n",
      "Trained words: 505600, Loss: 7.3704\n",
      "人得已病息\n",
      "Trained words: 508800, Loss: 7.3902\n",
      "何有在老中\n",
      "Trained words: 512000, Loss: 7.2355\n",
      "不思與人同\n",
      "Trained words: 515200, Loss: 7.0523\n",
      "朝鳥愁見春\n",
      "Trained words: 518400, Loss: 7.2885\n",
      "自聞君在家\n",
      "Trained words: 521600, Loss: 7.2911\n",
      "雲下山雨過\n",
      "Trained words: 524800, Loss: 7.2037\n",
      "時知時見情\n",
      "Trained words: 528000, Loss: 7.2428\n",
      "為歸此行別\n",
      "Trained words: 531200, Loss: 7.1910\n",
      "山日更江天\n",
      "Trained words: 534400, Loss: 7.1989\n",
      "此來來家相\n",
      "Trained words: 537600, Loss: 7.4534\n",
      "月下清南裏\n",
      "Trained words: 540800, Loss: 7.1292\n",
      "秋色新雲下\n",
      "Trained words: 544000, Loss: 7.1086\n",
      "春花生歸天\n",
      "Trained words: 547200, Loss: 7.1338\n",
      "天寒長落碧\n",
      "Trained words: 550400, Loss: 7.2744\n",
      "獨不為青天\n",
      "Trained words: 553600, Loss: 7.1893\n",
      "相有不思可\n",
      "Trained words: 556800, Loss: 7.3362\n",
      "日日不來心\n",
      "Trained words: 560000, Loss: 7.2999\n",
      "長君謝一雲\n",
      "Trained words: 563200, Loss: 7.4038\n",
      "何無為事心\n",
      "Trained words: 566400, Loss: 7.4165\n",
      "南上望青樓\n",
      "Trained words: 569600, Loss: 7.1895\n",
      "長日無人不\n",
      "Trained words: 572800, Loss: 7.2526\n",
      "春水煙泉秋\n",
      "Trained words: 576000, Loss: 7.2115\n",
      "自思長家少\n",
      "Trained words: 579200, Loss: 7.3747\n",
      "君日隨春鳥\n",
      "Trained words: 582400, Loss: 7.3572\n",
      "生遠上天日\n",
      "Trained words: 585600, Loss: 7.1574\n",
      "雲上長中長\n",
      "Trained words: 588800, Loss: 7.0405\n",
      "來日更聞人\n",
      "Trained words: 592000, Loss: 7.3292\n",
      "不思不去江\n",
      "Trained words: 595200, Loss: 7.4322\n",
      "白為欲風露\n",
      "Trained words: 598400, Loss: 7.4284\n",
      "故國已可無\n",
      "Trained words: 601600, Loss: 7.2289\n",
      "無年一未老\n",
      "Trained words: 604800, Loss: 7.3438\n",
      "一為金路山\n",
      "Trained words: 608000, Loss: 7.1823\n",
      "故路是山來\n",
      "Trained words: 611200, Loss: 7.1258\n",
      "獨與一別愁\n",
      "Trained words: 614400, Loss: 7.0868\n",
      "日入江煙去\n",
      "Trained words: 617600, Loss: 7.2962\n",
      "時日見行客\n",
      "Trained words: 620800, Loss: 7.2181\n",
      "應老亦如風\n",
      "Trained words: 624000, Loss: 7.1405\n",
      "今不知無道\n",
      "Trained words: 627200, Loss: 7.1570\n",
      "東門路邊水\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained words: 630400, Loss: 7.1824\n",
      "日歸江日愁\n",
      "Trained words: 633600, Loss: 7.2902\n",
      "一行三自時\n",
      "Trained words: 636800, Loss: 7.3621\n",
      "自以是道家\n",
      "Trained words: 640000, Loss: 7.2643\n",
      "相在在國貧\n",
      "Trained words: 643200, Loss: 7.3254\n",
      "此心從高侯\n",
      "Trained words: 646400, Loss: 7.4350\n",
      "自與無在家\n",
      "Trained words: 649600, Loss: 7.3834\n",
      "無病亦已道\n",
      "Trained words: 652800, Loss: 7.4657\n",
      "風香雪不不\n",
      "Trained words: 656000, Loss: 7.4343\n",
      "山望故同國\n",
      "Trained words: 659200, Loss: 7.6230\n",
      "獨花照山水\n",
      "Trained words: 662400, Loss: 7.6826\n",
      "人將自不病\n",
      "Trained words: 665600, Loss: 7.5080\n",
      "應是如風塵\n",
      "Trained words: 668800, Loss: 7.5150\n",
      "人來從道名\n",
      "Trained words: 672000, Loss: 7.5574\n",
      "無家古山門\n",
      "Trained words: 675200, Loss: 7.4634\n",
      "明雲落雲水\n",
      "Trained words: 678400, Loss: 7.4408\n",
      "君日思人心\n",
      "Trained words: 681600, Loss: 7.4773\n",
      "風秋上遠去\n",
      "Trained words: 684800, Loss: 7.7512\n",
      "東地與玉樓\n",
      "Trained words: 688000, Loss: 7.6424\n",
      "空明空雲樹\n",
      "Trained words: 691200, Loss: 7.9095\n",
      "何言若玉力\n",
      "Trained words: 694400, Loss: 7.6065\n",
      "自非朝為金\n",
      "Trained words: 697600, Loss: 7.7388\n",
      "青樹向雲樓\n",
      "Trained words: 700800, Loss: 7.5178\n",
      "自聞南山去\n",
      "Trained words: 704000, Loss: 7.5923\n",
      "一子不能言\n",
      "Trained words: 707200, Loss: 7.6016\n",
      "萬日知青路\n",
      "Trained words: 710400, Loss: 7.4406\n",
      "今朝上上水\n",
      "Trained words: 713600, Loss: 7.6405\n",
      "來去天東城\n",
      "Trained words: 716800, Loss: 7.7578\n",
      "自行天明春\n",
      "Trained words: 720000, Loss: 7.7856\n",
      "何歌所窮意\n",
      "Trained words: 723200, Loss: 7.6118\n",
      "春雪入玉樹\n",
      "Trained words: 726400, Loss: 7.6554\n",
      "雲有一時來\n",
      "Trained words: 729600, Loss: 7.6504\n",
      "萬門有人事\n",
      "Trained words: 732800, Loss: 7.5273\n",
      "歸年人同來\n",
      "Trained words: 736000, Loss: 7.3690\n",
      "不覺歸我人\n",
      "Trained words: 739200, Loss: 7.2781\n",
      "豈知見風華\n",
      "Trained words: 742400, Loss: 7.7408\n",
      "水花雪滿水\n",
      "Trained words: 745600, Loss: 7.7138\n",
      "何事日山曲\n",
      "Trained words: 748800, Loss: 7.4431\n",
      "不知我道不\n",
      "Trained words: 752000, Loss: 7.5280\n",
      "無時一人間\n",
      "Trained words: 755200, Loss: 7.3163\n",
      "高光三遠人\n",
      "Trained words: 758400, Loss: 7.3090\n",
      "此聞人遠中\n",
      "Trained words: 761600, Loss: 7.4427\n",
      "何人有同別\n",
      "Trained words: 764800, Loss: 7.5649\n",
      "何當有人情\n",
      "Trained words: 768000, Loss: 7.5627\n",
      "我見青春風\n",
      "Trained words: 771200, Loss: 7.3918\n",
      "如日日東雲\n",
      "Trained words: 774400, Loss: 7.3583\n",
      "無心有新氣\n",
      "Trained words: 777600, Loss: 7.4495\n",
      "此子生道身\n",
      "Trained words: 780800, Loss: 7.4533\n",
      "上波不自難\n",
      "Trained words: 784000, Loss: 7.4659\n",
      "心生無歸遊\n",
      "Trained words: 787200, Loss: 7.3396\n",
      "清明無相人\n",
      "Trained words: 790400, Loss: 7.2038\n",
      "空人將空子\n",
      "Trained words: 793600, Loss: 7.4001\n",
      "如日入幽路\n",
      "Trained words: 796800, Loss: 7.6801\n",
      "我處知人事\n",
      "Trained words: 800000, Loss: 7.5943\n",
      "日與一我人\n",
      "Trained words: 803200, Loss: 7.7348\n",
      "獨知不行離\n",
      "Trained words: 806400, Loss: 7.5190\n",
      "自如有家子\n",
      "Trained words: 809600, Loss: 7.6363\n",
      "青下無不思\n",
      "Trained words: 812800, Loss: 7.7618\n",
      "不相不相有\n",
      "Trained words: 816000, Loss: 7.6828\n",
      "今日為自作\n",
      "Trained words: 819200, Loss: 7.5661\n",
      "一人亦死腸\n",
      "Trained words: 822400, Loss: 7.5566\n",
      "不用何有之\n",
      "Trained words: 825600, Loss: 7.3701\n",
      "不見何我非\n",
      "Trained words: 828800, Loss: 7.8044\n",
      "不隨無年一\n",
      "Trained words: 832000, Loss: 8.0547\n",
      "長心各可能\n",
      "Trained words: 835200, Loss: 8.0473\n",
      "不將人時相\n",
      "Trained words: 838400, Loss: 7.8993\n",
      "自有金氣氣\n",
      "Trained words: 841600, Loss: 7.4128\n",
      "白露不可自\n",
      "Trained words: 844800, Loss: 7.6854\n",
      "相愛此處長\n",
      "Trained words: 848000, Loss: 7.6294\n",
      "君作五年不\n",
      "Trained words: 851200, Loss: 7.3738\n",
      "清花不復不\n",
      "Trained words: 854400, Loss: 7.4193\n",
      "風花生風泉\n",
      "Trained words: 857600, Loss: 7.3613\n",
      "春風不日何\n",
      "Trained words: 860800, Loss: 7.4590\n",
      "自覺心自見\n",
      "Trained words: 864000, Loss: 7.2064\n",
      "天氣不可聞\n",
      "Trained words: 867200, Loss: 7.1961\n",
      "風與來人子\n",
      "Trained words: 870400, Loss: 7.3497\n",
      "今日不在高\n",
      "Trained words: 873600, Loss: 7.3042\n",
      "君人無苦為\n",
      "Trained words: 876800, Loss: 7.3202\n",
      "我能何此日\n",
      "Trained words: 880000, Loss: 7.3730\n",
      "君無無由言\n",
      "Trained words: 883200, Loss: 7.0868\n",
      "此日已閑行\n",
      "Trained words: 886400, Loss: 7.1693\n",
      "青樹如有花\n",
      "Trained words: 889600, Loss: 7.2476\n",
      "日去有此日\n",
      "Trained words: 892800, Loss: 7.3600\n",
      "清月風滿風\n",
      "Trained words: 896000, Loss: 7.5555\n",
      "不識亦年日\n",
      "Trained words: 899200, Loss: 7.6435\n",
      "中坐天三詩\n",
      "Trained words: 902400, Loss: 7.7718\n",
      "上樹照碧庭\n",
      "Trained words: 905600, Loss: 7.5417\n",
      "朝夜南樓處\n",
      "Trained words: 908800, Loss: 7.5355\n",
      "今言所不如\n",
      "Trained words: 912000, Loss: 7.4291\n",
      "水頭東煙外\n",
      "Trained words: 915200, Loss: 7.5148\n",
      "人有去山陽\n",
      "Trained words: 918400, Loss: 7.4665\n",
      "生何非有人\n",
      "Trained words: 921600, Loss: 7.3952\n",
      "三年同酒月\n",
      "Trained words: 924800, Loss: 7.5075\n",
      "江湖西南城\n",
      "Trained words: 928000, Loss: 7.6255\n",
      "不隨一年事\n",
      "Trained words: 931200, Loss: 7.4460\n",
      "萬里十客心\n",
      "Trained words: 934400, Loss: 7.3307\n",
      "無君如雲樹\n",
      "Trained words: 937600, Loss: 7.4373\n",
      "無生與人不\n",
      "Trained words: 940800, Loss: 7.4499\n",
      "一詩與誰以\n",
      "Trained words: 944000, Loss: 7.3907\n",
      "人間處自行\n",
      "Trained words: 947200, Loss: 7.5312\n",
      "唯事為此身\n",
      "Trained words: 950400, Loss: 7.4262\n",
      "何君過上郡\n",
      "Trained words: 953600, Loss: 7.5659\n",
      "新酒日下行\n",
      "Trained words: 956800, Loss: 7.6452\n",
      "日日日下樓\n",
      "Trained words: 960000, Loss: 7.6591\n",
      "如春夜三酒\n",
      "Trained words: 963200, Loss: 7.5917\n",
      "唯不知此處\n",
      "Trained words: 966400, Loss: 7.4954\n",
      "一時似月下\n",
      "Trained words: 969600, Loss: 7.7690\n",
      "寒生盡塵氣\n",
      "Trained words: 972800, Loss: 7.5114\n",
      "為官非無賢\n",
      "Trained words: 976000, Loss: 7.7048\n",
      "何處複春上\n",
      "Trained words: 979200, Loss: 7.6122\n",
      "三地不留人\n",
      "Trained words: 982400, Loss: 7.3735\n",
      "君人應同客\n",
      "Trained words: 985600, Loss: 7.4639\n",
      "長日有無處\n",
      "Trained words: 988800, Loss: 7.6086\n",
      "東月忽夜夜\n",
      "Trained words: 992000, Loss: 7.3683\n",
      "人是有中行\n",
      "Trained words: 995200, Loss: 7.2326\n",
      "三時在南時\n",
      "Trained words: 998400, Loss: 7.2819\n",
      "雲聲在山山\n",
      "Trained words: 1001600, Loss: 7.1960\n",
      "不知相相到\n",
      "Trained words: 1004800, Loss: 7.3446\n",
      "君生如生家\n",
      "Trained words: 1008000, Loss: 7.2833\n",
      "何必知人事\n",
      "Trained words: 1011200, Loss: 7.4097\n",
      "不以難聲成\n",
      "Trained words: 1014400, Loss: 7.2026\n",
      "閑僧欲有詩\n",
      "Trained words: 1017600, Loss: 7.5857\n",
      "清聲似長色\n",
      "Trained words: 1020800, Loss: 7.4840\n",
      "天門下南原\n",
      "Trained words: 1024000, Loss: 7.4470\n",
      "唯病相可自\n",
      "Trained words: 1027200, Loss: 7.3767\n",
      "未看還心在\n",
      "Trained words: 1030400, Loss: 7.4823\n",
      "山中不是不\n",
      "Trained words: 1033600, Loss: 7.1758\n",
      "朝為長何處\n",
      "Trained words: 1036800, Loss: 7.3332\n",
      "一山清風光\n",
      "Trained words: 1040000, Loss: 7.7297\n",
      "長看更長後\n",
      "Trained words: 1043200, Loss: 7.8546\n",
      "天秋出西邊\n",
      "Trained words: 1046400, Loss: 7.7353\n",
      "如何因同不\n",
      "Trained words: 1049600, Loss: 7.5601\n",
      "自在西客來\n",
      "Trained words: 1052800, Loss: 7.5370\n",
      "自我當日時\n",
      "Trained words: 1056000, Loss: 7.2475\n",
      "春草草山下\n",
      "Trained words: 1059200, Loss: 7.2333\n",
      "自應愁與醉\n",
      "Trained words: 1062400, Loss: 7.3529\n",
      "風風入酒長\n",
      "Trained words: 1065600, Loss: 7.6413\n",
      "山月春上雲\n",
      "Trained words: 1068800, Loss: 7.6292\n",
      "無心少千陵\n",
      "Trained words: 1072000, Loss: 7.5684\n",
      "萬時見高樓\n",
      "Trained words: 1075200, Loss: 7.8136\n",
      "無君是春意\n",
      "Trained words: 1078400, Loss: 7.8591\n",
      "雲雨不可心\n",
      "Trained words: 1081600, Loss: 7.7048\n",
      "天外碧門宮\n",
      "Trained words: 1084800, Loss: 7.4516\n",
      "風入千里里\n",
      "Trained words: 1088000, Loss: 7.3214\n",
      "有客是道名\n",
      "Trained words: 1091200, Loss: 7.6004\n",
      "一日過門路\n",
      "Trained words: 1094400, Loss: 7.4056\n",
      "清陰見高寺\n",
      "Trained words: 1097600, Loss: 7.1723\n",
      "人聞君風晚\n",
      "Trained words: 1100800, Loss: 7.2299\n",
      "無情遠中地\n",
      "Trained words: 1104000, Loss: 7.3061\n",
      "長子別歸雲\n",
      "Trained words: 1107200, Loss: 7.4827\n",
      "山邊漢相夜\n",
      "Trained words: 1110400, Loss: 7.6233\n",
      "白光滿草生\n",
      "Trained words: 1113600, Loss: 7.4861\n",
      "豈得非賢君\n",
      "Trained words: 1116800, Loss: 7.5383\n",
      "白生正舊行\n",
      "Trained words: 1120000, Loss: 7.7071\n",
      "今日又還此\n",
      "Trained words: 1123200, Loss: 7.5160\n",
      "日照雙樓雲\n",
      "Trained words: 1126400, Loss: 7.5199\n",
      "清明月半日\n",
      "Trained words: 1129600, Loss: 7.3210\n",
      "此人難相吟\n",
      "Trained words: 1132800, Loss: 7.4179\n",
      "一裏夜秋陰\n",
      "Trained words: 1136000, Loss: 7.3487\n",
      "新後不多遊\n",
      "Trained words: 1139200, Loss: 7.5711\n",
      "山水連水湘\n",
      "Trained words: 1142400, Loss: 8.0285\n",
      "秋風一寒雨\n",
      "Trained words: 1145600, Loss: 7.3493\n",
      "誰見白雲聲\n",
      "Trained words: 1148800, Loss: 7.5433\n",
      "南天不得心\n",
      "Trained words: 1152000, Loss: 7.2565\n",
      "花雨有新盡\n",
      "Trained words: 1155200, Loss: 7.1127\n",
      "清陽盡自成\n",
      "Trained words: 1158400, Loss: 7.3659\n",
      "相見人時從\n",
      "Trained words: 1161600, Loss: 7.3311\n",
      "時盡亦相忘\n",
      "Trained words: 1164800, Loss: 7.0463\n",
      "江城上上路\n",
      "Trained words: 1168000, Loss: 7.3341\n",
      "春草亦見地\n",
      "Trained words: 1171200, Loss: 7.5657\n",
      "月中白雲中\n",
      "Trained words: 1174400, Loss: 7.2261\n",
      "春色一年晚\n",
      "Trained words: 1177600, Loss: 7.3291\n",
      "中陽多有客\n",
      "Trained words: 1180800, Loss: 7.4484\n",
      "如我如誰得\n",
      "Trained words: 1184000, Loss: 7.7179\n",
      "不得有離處\n",
      "Trained words: 1187200, Loss: 8.0499\n",
      "此到路山遙\n",
      "Trained words: 1190400, Loss: 7.8799\n",
      "南樓出不下\n",
      "Trained words: 1193600, Loss: 7.7937\n",
      "如鳥出玉階\n",
      "Trained words: 1196800, Loss: 7.7485\n",
      "雲雲入一人\n",
      "Trained words: 1200000, Loss: 7.9870\n",
      "秋滿石上峰\n",
      "Trained words: 1203200, Loss: 7.8005\n",
      "天生不及歸\n",
      "Trained words: 1206400, Loss: 7.7612\n",
      "萬年為其名\n",
      "Trained words: 1209600, Loss: 7.7455\n",
      "相能如我與\n",
      "Trained words: 1212800, Loss: 7.7245\n",
      "何是真其名\n",
      "Trained words: 1216000, Loss: 7.8745\n",
      "一將皆相思\n",
      "Trained words: 1219200, Loss: 7.6035\n",
      "寒雨照秋光\n",
      "Trained words: 1222400, Loss: 7.3622\n",
      "有時若為身\n",
      "Trained words: 1225600, Loss: 7.1789\n",
      "月色上門人\n",
      "Trained words: 1228800, Loss: 7.3819\n",
      "行路猶何聞\n",
      "Trained words: 1232000, Loss: 7.3429\n",
      "孤居不無所\n",
      "Trained words: 1235200, Loss: 7.4255\n",
      "行年當萬歲\n",
      "Trained words: 1238400, Loss: 7.3877\n",
      "一期不聞音\n",
      "Trained words: 1241600, Loss: 7.5902\n",
      "東地多不知\n",
      "Trained words: 1244800, Loss: 7.5499\n",
      "風生落草色\n",
      "Trained words: 1248000, Loss: 7.6632\n",
      "終將不可是\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained words: 1251200, Loss: 7.4508\n",
      "何有此別處\n",
      "Trained words: 1254400, Loss: 7.6013\n",
      "猶得更何親\n",
      "Trained words: 1257600, Loss: 7.3093\n",
      "時生事已心\n",
      "Trained words: 1260800, Loss: 7.5733\n",
      "人時是長道\n",
      "Trained words: 1264000, Loss: 7.5802\n",
      "無心應何處\n",
      "Trained words: 1267200, Loss: 7.8279\n",
      "一去又空清\n",
      "Trained words: 1270400, Loss: 7.3442\n",
      "不聞此遊清\n",
      "Trained words: 1273600, Loss: 7.1114\n",
      "無身不見何\n",
      "Trained words: 1276800, Loss: 7.5547\n",
      "人為一塵重\n",
      "Trained words: 1280000, Loss: 7.7723\n",
      "朝子一重城\n",
      "Trained words: 1283200, Loss: 7.3441\n",
      "風雨過白雲\n",
      "Trained words: 1286400, Loss: 7.4081\n",
      "歸春在長人\n",
      "Trained words: 1289600, Loss: 7.6867\n",
      "未能更相知\n",
      "Trained words: 1292800, Loss: 7.3344\n",
      "南陵向漢州\n",
      "Trained words: 1296000, Loss: 7.4335\n",
      "何能當此不\n",
      "Trained words: 1299200, Loss: 7.5997\n",
      "未得同山來\n",
      "Trained words: 1302400, Loss: 7.4228\n",
      "一時不得見\n",
      "Trained words: 1305600, Loss: 7.5728\n",
      "不得為雲者\n",
      "Trained words: 1308800, Loss: 7.3044\n",
      "朝當天臺風\n",
      "Trained words: 1312000, Loss: 7.5932\n",
      "孤山天邊裏\n",
      "Trained words: 1315200, Loss: 7.3664\n",
      "何為事相同\n",
      "Trained words: 1318400, Loss: 7.8209\n",
      "今家家所外\n",
      "Trained words: 1321600, Loss: 7.6609\n",
      "秋雨正一杯\n",
      "Trained words: 1324800, Loss: 7.5066\n",
      "江樹又已成\n",
      "Trained words: 1328000, Loss: 7.5314\n",
      "無名出天地\n",
      "Trained words: 1331200, Loss: 7.6395\n",
      "相逢幾日日\n",
      "Trained words: 1334400, Loss: 7.4962\n",
      "白鳥立空中\n",
      "Trained words: 1337600, Loss: 7.6731\n",
      "應應過地上\n",
      "Trained words: 1340800, Loss: 7.6733\n",
      "獨生無心期\n",
      "Trained words: 1344000, Loss: 7.5988\n",
      "長生不相見\n",
      "Trained words: 1347200, Loss: 7.6951\n",
      "不知時多情\n",
      "Trained words: 1350400, Loss: 7.7354\n",
      "天雲遠山路\n",
      "Trained words: 1353600, Loss: 7.6364\n",
      "孤心與難稀\n",
      "Trained words: 1356800, Loss: 7.6281\n",
      "還隨一萬里\n",
      "Trained words: 1360000, Loss: 7.8399\n",
      "自我如何事\n",
      "Trained words: 1363200, Loss: 8.3304\n",
      "相不自敢無\n",
      "Trained words: 1366400, Loss: 8.0311\n",
      "何計已可識\n",
      "Trained words: 1369600, Loss: 7.6829\n",
      "一衣新未夜\n",
      "Trained words: 1372800, Loss: 7.4737\n",
      "不時風涼夜\n",
      "Trained words: 1376000, Loss: 7.5873\n",
      "一言玉衣玉\n",
      "Trained words: 1379200, Loss: 7.7638\n",
      "我言君可同\n",
      "Trained words: 1382400, Loss: 7.5871\n",
      "無意不無愁\n",
      "Trained words: 1385600, Loss: 7.5026\n",
      "行心不何見\n",
      "Trained words: 1388800, Loss: 7.6552\n",
      "人覺無世得\n",
      "Trained words: 1392000, Loss: 7.3789\n",
      "寒霞有人去\n",
      "Trained words: 1395200, Loss: 7.4249\n",
      "歸去一山裏\n",
      "Trained words: 1398400, Loss: 7.7048\n",
      "朝來白雲去\n",
      "Trained words: 1401600, Loss: 7.5336\n",
      "何必不如水\n",
      "Trained words: 1404800, Loss: 7.5574\n",
      "孤舟不可心\n",
      "Trained words: 1408000, Loss: 7.3875\n",
      "今心亦何情\n",
      "Trained words: 1411200, Loss: 7.3698\n",
      "江城水東岸\n",
      "Trained words: 1414400, Loss: 7.5152\n",
      "一日月山僧\n",
      "Trained words: 1417600, Loss: 7.4198\n",
      "長看在山枝\n",
      "Trained words: 1420800, Loss: 7.6034\n",
      "夜聞林不有\n",
      "Trained words: 1424000, Loss: 7.5937\n",
      "花葉落花中\n",
      "Trained words: 1427200, Loss: 7.5493\n",
      "雲來一聲聲\n",
      "Trained words: 1430400, Loss: 7.6172\n",
      "人知知此地\n",
      "Trained words: 1433600, Loss: 7.6397\n",
      "中世向何歸\n",
      "Trained words: 1436800, Loss: 7.6029\n",
      "千月還前去\n",
      "Trained words: 1440000, Loss: 7.4743\n",
      "千峰皆萬樹\n",
      "Trained words: 1443200, Loss: 7.4579\n",
      "空峰多此去\n",
      "Trained words: 1446400, Loss: 7.5102\n",
      "寒然複已別\n",
      "Trained words: 1449600, Loss: 7.3900\n",
      "無時不苦不\n",
      "Trained words: 1452800, Loss: 7.4030\n",
      "應見一餘人\n",
      "Trained words: 1456000, Loss: 7.4276\n",
      "高月上雲峰\n",
      "Trained words: 1459200, Loss: 7.4337\n",
      "未覺多人多\n",
      "Trained words: 1462400, Loss: 7.4370\n",
      "風風遠去望\n",
      "Trained words: 1465600, Loss: 7.5237\n",
      "閑行未老春\n",
      "Trained words: 1468800, Loss: 7.9338\n",
      "此言誰逢事\n",
      "Trained words: 1472000, Loss: 7.6940\n",
      "秋露不見不\n",
      "Trained words: 1475200, Loss: 7.5105\n",
      "雲影連空影\n",
      "Trained words: 1478400, Loss: 7.6230\n",
      "今名何人樂\n",
      "Trained words: 1481600, Loss: 7.8215\n",
      "日知此人無\n",
      "Trained words: 1484800, Loss: 7.6384\n",
      "雲風上萬行\n",
      "Trained words: 1488000, Loss: 7.6409\n",
      "南江島雲霞\n",
      "Trained words: 1491200, Loss: 7.7153\n",
      "今有幾遊人\n",
      "Trained words: 1494400, Loss: 7.6138\n",
      "風落動衣痕\n",
      "Trained words: 1497600, Loss: 7.5958\n",
      "日日回流鳥\n",
      "Trained words: 1500800, Loss: 7.8670\n",
      "何處有金泉\n",
      "Trained words: 1504000, Loss: 7.6271\n",
      "花葉樹長寒\n",
      "Trained words: 1507200, Loss: 7.8284\n",
      "長日欲花花\n",
      "Trained words: 1510400, Loss: 7.8153\n",
      "月月臨雲影\n",
      "Trained words: 1513600, Loss: 7.8496\n",
      "自從人盡長\n",
      "Trained words: 1516800, Loss: 7.6622\n",
      "還來來去路\n",
      "Trained words: 1520000, Loss: 7.5120\n",
      "自然浮然空\n",
      "Trained words: 1523200, Loss: 7.5738\n",
      "相來還自來\n",
      "Trained words: 1526400, Loss: 7.6191\n",
      "有物難在空\n",
      "Trained words: 1529600, Loss: 7.6220\n",
      "不來人傷死\n",
      "Trained words: 1532800, Loss: 7.5469\n",
      "秋雲無為處\n",
      "Trained words: 1536000, Loss: 7.5592\n",
      "此知南月月\n",
      "Trained words: 1539200, Loss: 7.6880\n",
      "寒歌玉金刀\n",
      "Trained words: 1542400, Loss: 7.5857\n",
      "有君一百年\n",
      "Trained words: 1545600, Loss: 7.4400\n",
      "金女不驚思\n",
      "Trained words: 1548800, Loss: 7.3989\n",
      "朝來過雲回\n",
      "Trained words: 1552000, Loss: 7.5399\n",
      "萬古長未識\n",
      "Trained words: 1555200, Loss: 7.8543\n",
      "空雲無天上\n",
      "Trained words: 1558400, Loss: 7.9099\n",
      "還來見一字\n",
      "Trained words: 1561600, Loss: 7.7921\n",
      "天上海中月\n",
      "Trained words: 1564800, Loss: 7.6422\n",
      "一月光華裏\n",
      "Trained words: 1568000, Loss: 7.6571\n",
      "山門出馬城\n",
      "Trained words: 1571200, Loss: 7.5298\n",
      "何處有何親\n",
      "Trained words: 1574400, Loss: 7.7542\n",
      "山日已歸飛\n",
      "Trained words: 1577600, Loss: 7.8393\n",
      "千人同何得\n",
      "Trained words: 1580800, Loss: 7.6857\n",
      "秋山北闕闕\n",
      "Trained words: 1584000, Loss: 7.4921\n",
      "天下九原氣\n",
      "Trained words: 1587200, Loss: 7.5850\n",
      "莫憐有意同\n",
      "Trained words: 1590400, Loss: 7.6348\n",
      "不能相歸人\n",
      "Trained words: 1593600, Loss: 7.6936\n",
      "今日今行來\n",
      "Trained words: 1596800, Loss: 7.7099\n",
      "山有萬里流\n",
      "Trained words: 1600000, Loss: 7.6136\n",
      "君來遠子郎\n",
      "Trained words: 1603200, Loss: 7.6965\n",
      "風葉露凝弦\n",
      "Trained words: 1606400, Loss: 7.4882\n",
      "朝朝天臺裏\n",
      "Trained words: 1609600, Loss: 7.6234\n",
      "白沙頭雁路\n",
      "Trained words: 1612800, Loss: 7.7350\n",
      "相憐大相回\n",
      "Trained words: 1616000, Loss: 7.7725\n",
      "幽花泛酒發\n",
      "Trained words: 1619200, Loss: 7.6916\n",
      "誰應複望行\n",
      "Trained words: 1622400, Loss: 7.7501\n",
      "時年故情不\n",
      "Trained words: 1625600, Loss: 7.6476\n",
      "南來白楊柳\n",
      "Trained words: 1628800, Loss: 7.7193\n",
      "落葉紅枝間\n",
      "Trained words: 1632000, Loss: 7.8382\n",
      "飛馬歸春遠\n",
      "Trained words: 1635200, Loss: 7.7375\n",
      "玉殿下新席\n",
      "Trained words: 1638400, Loss: 7.5738\n",
      "風景自可時\n",
      "Trained words: 1641600, Loss: 7.7262\n",
      "誰能入江水\n",
      "Trained words: 1644800, Loss: 7.5326\n",
      "相思故國人\n",
      "Trained words: 1648000, Loss: 7.7777\n",
      "一物猶成白\n",
      "Trained words: 1651200, Loss: 7.5424\n",
      "明秋南曲月\n",
      "Trained words: 1654400, Loss: 7.7243\n",
      "春日暮何來\n",
      "Trained words: 1657600, Loss: 7.5993\n",
      "為君共思期\n",
      "Trained words: 1660800, Loss: 7.5438\n",
      "自有江天水\n",
      "Trained words: 1664000, Loss: 7.6748\n",
      "誰聞洛王子\n",
      "Trained words: 1667200, Loss: 7.6519\n",
      "有日多家鄉\n",
      "Trained words: 1670400, Loss: 7.7439\n",
      "千樹斷山前\n",
      "Trained words: 1673600, Loss: 7.7293\n",
      "寒月出西雲\n",
      "Trained words: 1676800, Loss: 7.6712\n",
      "青日雲中時\n",
      "Trained words: 1680000, Loss: 7.8713\n",
      "風雨滿花色\n",
      "Trained words: 1683200, Loss: 7.6330\n",
      "白髮出秋中\n",
      "Trained words: 1686400, Loss: 7.7111\n",
      "何日三餘會\n",
      "Trained words: 1689600, Loss: 7.7080\n",
      "一朝入舊天\n",
      "Trained words: 1692800, Loss: 7.7609\n",
      "誰知不歎歸\n",
      "Trained words: 1696000, Loss: 7.6352\n",
      "風氣不可憐\n",
      "Trained words: 1699200, Loss: 7.6140\n",
      "春月自誰時\n",
      "Trained words: 1702400, Loss: 7.6080\n",
      "時聞何人語\n",
      "Trained words: 1705600, Loss: 7.6156\n",
      "青峰自相窮\n",
      "Trained words: 1708800, Loss: 7.6304\n",
      "秋生複為春\n",
      "Trained words: 1712000, Loss: 7.7397\n",
      "天來不復過\n",
      "Trained words: 1715200, Loss: 7.5357\n",
      "一時出金溝\n",
      "Trained words: 1718400, Loss: 7.5867\n",
      "此來思未悲\n",
      "Trained words: 1721600, Loss: 7.5420\n",
      "行客出人遊\n",
      "Trained words: 1724800, Loss: 7.5642\n",
      "青門不可憐\n",
      "Trained words: 1728000, Loss: 7.6553\n",
      "花柳盡落林\n",
      "Trained words: 1731200, Loss: 7.6524\n",
      "雲影開前路\n",
      "Trained words: 1734400, Loss: 7.5476\n",
      "空色天無深\n",
      "Trained words: 1737600, Loss: 7.6458\n",
      "一朝朝朝晚\n",
      "Trained words: 1740800, Loss: 7.8478\n",
      "無息為人家\n",
      "Trained words: 1744000, Loss: 7.9114\n",
      "不知複君有\n",
      "Trained words: 1747200, Loss: 7.3675\n",
      "天天北漢車\n",
      "Trained words: 1750400, Loss: 7.6578\n",
      "歸林入江津\n",
      "Trained words: 1753600, Loss: 7.5949\n",
      "春色欲雲林\n",
      "Trained words: 1756800, Loss: 7.6427\n",
      "歸山未往歸\n",
      "Trained words: 1760000, Loss: 7.5265\n",
      "獨坐為一書\n",
      "Trained words: 1763200, Loss: 7.2995\n",
      "君來發羽杯\n",
      "Trained words: 1766400, Loss: 7.2890\n",
      "山路遠陵上\n",
      "Trained words: 1769600, Loss: 7.4047\n",
      "為軍與君言\n",
      "Trained words: 1772800, Loss: 7.3759\n",
      "三載向秦州\n",
      "Trained words: 1776000, Loss: 7.5553\n",
      "山向白雲盡\n",
      "Trained words: 1779200, Loss: 7.7819\n",
      "不相逢月月\n",
      "Trained words: 1782400, Loss: 7.7845\n",
      "天天去歸帆\n",
      "Trained words: 1785600, Loss: 7.5849\n",
      "不知遠田田\n",
      "Trained words: 1788800, Loss: 7.7142\n",
      "相得得其以\n",
      "Trained words: 1792000, Loss: 7.6465\n",
      "孤舟何足見\n",
      "Trained words: 1795200, Loss: 7.5844\n",
      "水岸如河波\n",
      "Trained words: 1798400, Loss: 7.7409\n",
      "獨與何難是\n",
      "Trained words: 1801600, Loss: 7.7199\n",
      "朝歌舞還閑\n",
      "Trained words: 1804800, Loss: 7.7240\n",
      "君生萬里騎\n",
      "Trained words: 1808000, Loss: 7.6384\n",
      "無然風江裏\n",
      "Trained words: 1811200, Loss: 7.6025\n",
      "相堪待一月\n",
      "Trained words: 1814400, Loss: 7.7061\n",
      "空月日相歸\n",
      "Trained words: 1817600, Loss: 7.6942\n",
      "不言將世客\n",
      "Trained words: 1820800, Loss: 7.6456\n",
      "萬里江東上\n",
      "Trained words: 1824000, Loss: 7.5348\n",
      "長日複然然\n",
      "Trained words: 1827200, Loss: 7.6591\n",
      "此君長風去\n",
      "Trained words: 1830400, Loss: 7.5374\n",
      "天堂望樓陽\n",
      "Trained words: 1833600, Loss: 7.5831\n",
      "歸時當何處\n",
      "Trained words: 1836800, Loss: 7.5450\n",
      "君知何由知\n",
      "Trained words: 1840000, Loss: 7.5599\n",
      "行來楚陵來\n",
      "Trained words: 1843200, Loss: 7.5312\n",
      "千江有相安\n",
      "Trained words: 1846400, Loss: 7.4345\n",
      "朝當謝公陵\n",
      "Trained words: 1849600, Loss: 7.5412\n",
      "長日竟還來\n",
      "Trained words: 1852800, Loss: 7.5771\n",
      "相訪別人人\n",
      "Trained words: 1856000, Loss: 7.7664\n",
      "風吹下人歸\n",
      "Trained words: 1859200, Loss: 7.6941\n",
      "幽居在萬事\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained words: 1862400, Loss: 7.6268\n",
      "還去在天雲\n",
      "Trained words: 1865600, Loss: 7.7231\n",
      "千年不見時\n",
      "Trained words: 1868800, Loss: 7.6695\n",
      "一言無所以\n",
      "Trained words: 1872000, Loss: 7.6871\n",
      "千里忽自難\n",
      "Trained words: 1875200, Loss: 7.6569\n",
      "風煙綠綠水\n",
      "Trained words: 1878400, Loss: 7.6380\n",
      "獨念君子遠\n",
      "Trained words: 1881600, Loss: 7.6904\n",
      "青樓掩玉門\n",
      "Trained words: 1884800, Loss: 7.7405\n",
      "相聞西陵客\n",
      "Trained words: 1888000, Loss: 7.7267\n",
      "歸馬到天門\n",
      "Trained words: 1891200, Loss: 7.6721\n",
      "遠水山西山\n",
      "Trained words: 1894400, Loss: 7.5535\n",
      "東川在東閣\n",
      "Trained words: 1897600, Loss: 7.6284\n",
      "日上吳家處\n",
      "Trained words: 1900800, Loss: 7.5756\n",
      "白玉行丹屋\n",
      "Trained words: 1904000, Loss: 7.6952\n",
      "長馬皆相識\n",
      "Trained words: 1907200, Loss: 7.5872\n",
      "幽人人遠山\n",
      "Trained words: 1910400, Loss: 7.6414\n",
      "白雲過西客\n",
      "Trained words: 1913600, Loss: 7.8717\n",
      "誰堪複時時\n",
      "Trained words: 1916800, Loss: 7.7772\n",
      "山雲何處有\n",
      "Trained words: 1920000, Loss: 7.6208\n",
      "心心有時同\n",
      "Trained words: 1923200, Loss: 7.7898\n",
      "明月已日日\n",
      "Trained words: 1926400, Loss: 7.8553\n",
      "何人一不見\n",
      "Trained words: 1929600, Loss: 8.0248\n",
      "山雲不可見\n",
      "Trained words: 1932800, Loss: 7.9573\n",
      "春日暮悠悠\n",
      "Trained words: 1936000, Loss: 7.7303\n",
      "終知方與事\n",
      "Trained words: 1939200, Loss: 7.8627\n",
      "雲去長蒼路\n",
      "Trained words: 1942400, Loss: 7.8821\n",
      "清明照花生\n",
      "Trained words: 1945600, Loss: 7.9350\n",
      "雲壁出不分\n",
      "Trained words: 1948800, Loss: 7.9382\n",
      "萬事尚中道\n",
      "Trained words: 1952000, Loss: 8.0260\n",
      "何以尚可存\n",
      "Trained words: 1955200, Loss: 7.9091\n",
      "不見長門近\n",
      "Trained words: 1958400, Loss: 7.9765\n",
      "遠山春景日\n",
      "Trained words: 1961600, Loss: 7.9906\n",
      "三國不可親\n",
      "Trained words: 1964800, Loss: 7.8325\n",
      "何當此知意\n",
      "Trained words: 1968000, Loss: 7.6185\n",
      "白露露如霜\n",
      "Trained words: 1971200, Loss: 7.8190\n",
      "一峰上青門\n",
      "Trained words: 1974400, Loss: 7.6035\n",
      "萬道皆相待\n",
      "Trained words: 1977600, Loss: 7.5691\n",
      "江上客雲秋\n",
      "Trained words: 1980800, Loss: 7.7975\n",
      "今在萬里無\n",
      "Trained words: 1984000, Loss: 7.6685\n",
      "一詩且醉行\n",
      "Trained words: 1987200, Loss: 8.0004\n",
      "南客有高居\n",
      "Trained words: 1990400, Loss: 7.5833\n",
      "歸客老江山\n",
      "Trained words: 1993600, Loss: 7.7849\n",
      "此日到東州\n",
      "Trained words: 1996800, Loss: 7.8727\n",
      "萬木清清素\n",
      "Trained words: 2000000, Loss: 7.8837\n",
      "青冥無所見\n",
      "Trained words: 2003200, Loss: 7.7535\n",
      "一言複易不\n",
      "Trained words: 2006400, Loss: 7.7228\n",
      "自有一酒春\n",
      "Trained words: 2009600, Loss: 7.6963\n",
      "雲霄雲霄霄\n",
      "Trained words: 2012800, Loss: 7.4457\n",
      "萬里有江波\n",
      "Trained words: 2016000, Loss: 7.5901\n",
      "此人人不到\n",
      "Trained words: 2019200, Loss: 7.7184\n",
      "白鶴自同風\n",
      "Trained words: 2022400, Loss: 7.5282\n",
      "一日不相忘\n",
      "Trained words: 2025600, Loss: 7.6607\n",
      "自知一老心\n",
      "Trained words: 2028800, Loss: 7.5618\n",
      "萬里不辭書\n",
      "Trained words: 2032000, Loss: 7.5299\n",
      "江山上漢隅\n",
      "Trained words: 2035200, Loss: 7.9148\n",
      "此時在江南\n",
      "Trained words: 2038400, Loss: 7.6138\n",
      "青頭問誰君\n",
      "Trained words: 2041600, Loss: 7.4871\n",
      "獨往思此人\n",
      "Trained words: 2044800, Loss: 7.5039\n",
      "水水深山水\n",
      "Trained words: 2048000, Loss: 7.5899\n",
      "獨路難依心\n",
      "Trained words: 2051200, Loss: 7.7260\n",
      "不如天上樹\n",
      "Trained words: 2054400, Loss: 7.6054\n",
      "行歌複送酒\n",
      "Trained words: 2057600, Loss: 7.6748\n",
      "遠期山下門\n",
      "Trained words: 2060800, Loss: 7.7089\n",
      "自有秦家路\n",
      "Trained words: 2064000, Loss: 7.7914\n",
      "山口有東流\n",
      "Trained words: 2067200, Loss: 7.6562\n",
      "中客欲相思\n",
      "Trained words: 2070400, Loss: 7.5861\n",
      "秋雲動天末\n",
      "Trained words: 2073600, Loss: 7.6658\n",
      "無客心複何\n",
      "Trained words: 2076800, Loss: 7.6203\n",
      "新日夜相思\n",
      "Trained words: 2080000, Loss: 7.8075\n",
      "南興在長洲\n",
      "Trained words: 2083200, Loss: 7.5813\n",
      "此去一朝歸\n",
      "Trained words: 2086400, Loss: 7.4811\n",
      "何用向雲生\n",
      "Trained words: 2089600, Loss: 7.5595\n",
      "孤居漢海南\n",
      "Trained words: 2092800, Loss: 7.7931\n",
      "遠行遠望長\n",
      "Trained words: 2096000, Loss: 7.8419\n",
      "萬人知舊老\n",
      "Trained words: 2099200, Loss: 7.6205\n",
      "天生上石陰\n",
      "Trained words: 2102400, Loss: 7.6782\n",
      "三湖多春暮\n",
      "Trained words: 2105600, Loss: 7.6442\n",
      "歸山青山樹\n",
      "Trained words: 2108800, Loss: 7.5393\n",
      "自言空水落\n",
      "Trained words: 2112000, Loss: 7.4160\n",
      "故人見何歸\n",
      "Trained words: 2115200, Loss: 7.5660\n",
      "唯居不未識\n",
      "Trained words: 2118400, Loss: 7.6840\n",
      "風光落古陰\n",
      "Trained words: 2121600, Loss: 7.5246\n",
      "春年不與春\n",
      "Trained words: 2124800, Loss: 7.5505\n",
      "江波海流悠\n",
      "Trained words: 2128000, Loss: 7.4822\n",
      "江邊道道稀\n",
      "Trained words: 2131200, Loss: 7.6702\n",
      "空陰生無不\n",
      "Trained words: 2134400, Loss: 7.6318\n",
      "還人共不回\n",
      "Trained words: 2137600, Loss: 7.6612\n",
      "無人此離別\n",
      "Trained words: 2140800, Loss: 7.6296\n",
      "莫是天中客\n",
      "Trained words: 2144000, Loss: 7.7376\n",
      "還人不相見\n",
      "Trained words: 2147200, Loss: 7.7589\n",
      "青山白上地\n",
      "Trained words: 2150400, Loss: 7.8269\n",
      "野與客遊人\n",
      "Trained words: 2153600, Loss: 7.7989\n",
      "自然有難會\n",
      "Trained words: 2156800, Loss: 7.8967\n",
      "花日未還來\n",
      "Trained words: 2160000, Loss: 8.0044\n",
      "時月映江開\n",
      "Trained words: 2163200, Loss: 7.9128\n",
      "不見秋林不\n",
      "Trained words: 2166400, Loss: 7.7837\n",
      "人路皆悠海\n",
      "Trained words: 2169600, Loss: 7.9022\n",
      "朝陽見此日\n",
      "Trained words: 2172800, Loss: 7.8225\n",
      "歸國在空心\n",
      "Trained words: 2176000, Loss: 7.7876\n",
      "風光月上春\n",
      "Trained words: 2179200, Loss: 7.8403\n",
      "空煙白日前\n",
      "Trained words: 2182400, Loss: 7.9753\n",
      "時當紫山山\n",
      "Trained words: 2185600, Loss: 7.8978\n",
      "遠路雲連岸\n",
      "Trained words: 2188800, Loss: 8.2324\n",
      "一里多山樹\n",
      "Trained words: 2192000, Loss: 7.9524\n",
      "清景不回首\n",
      "Trained words: 2195200, Loss: 7.9644\n",
      "三湖入江塘\n",
      "Trained words: 2198400, Loss: 7.8173\n",
      "獨向雙蒼茫\n",
      "Trained words: 2201600, Loss: 7.8483\n",
      "寒馬不可知\n",
      "Trained words: 2204800, Loss: 7.9451\n",
      "行行非我者\n",
      "Trained words: 2208000, Loss: 7.7509\n",
      "南陽望萬里\n",
      "Trained words: 2211200, Loss: 7.7638\n",
      "日開門地近\n",
      "Trained words: 2214400, Loss: 8.0731\n",
      "天寒雨雲出\n",
      "Trained words: 2217600, Loss: 8.0885\n",
      "不謂東山有\n",
      "Trained words: 2220800, Loss: 7.9589\n",
      "一人相複有\n",
      "Trained words: 2224000, Loss: 7.8657\n",
      "不聞我有情\n",
      "Trained words: 2227200, Loss: 8.0111\n",
      "幽人已所非\n",
      "Trained words: 2230400, Loss: 7.8440\n",
      "三年不能時\n",
      "Trained words: 2233600, Loss: 7.7069\n",
      "清思白露開\n",
      "Trained words: 2236800, Loss: 7.6092\n",
      "時如日遠遠\n",
      "Trained words: 2240000, Loss: 7.9239\n",
      "秋華映花月\n",
      "Trained words: 2243200, Loss: 8.0786\n",
      "為我乃相思\n",
      "Trained words: 2246400, Loss: 7.7316\n",
      "時行一餘情\n",
      "Trained words: 2249600, Loss: 7.8248\n",
      "東城有古堂\n",
      "Trained words: 2252800, Loss: 7.6911\n",
      "自無還是日\n",
      "Trained words: 2256000, Loss: 7.5676\n",
      "有我無言笑\n",
      "Trained words: 2259200, Loss: 7.6849\n",
      "日何必何用\n",
      "Trained words: 2262400, Loss: 7.8404\n",
      "三十五千天\n",
      "Trained words: 2265600, Loss: 7.8714\n",
      "天陰變大道\n",
      "Trained words: 2268800, Loss: 7.6985\n",
      "無為無為意\n",
      "Trained words: 2272000, Loss: 7.6236\n",
      "中物不能言\n",
      "Trained words: 2275200, Loss: 7.7073\n",
      "山是春雲多\n",
      "Trained words: 2278400, Loss: 7.7584\n",
      "歸時有其情\n",
      "Trained words: 2281600, Loss: 7.7484\n",
      "天地不驚風\n",
      "Trained words: 2284800, Loss: 7.6164\n",
      "高生既為人\n",
      "Trained words: 2288000, Loss: 7.4546\n",
      "行事不得死\n",
      "Trained words: 2291200, Loss: 7.5863\n",
      "誰是非無知\n",
      "Trained words: 2294400, Loss: 7.8968\n",
      "獨吟無意說\n",
      "Trained words: 2297600, Loss: 7.8072\n",
      "唯有為我家\n",
      "Trained words: 2300800, Loss: 8.0105\n",
      "秋月向孤舟\n",
      "Trained words: 2304000, Loss: 7.8468\n",
      "一食不敢親\n",
      "Trained words: 2307200, Loss: 7.8084\n",
      "無知如此日\n",
      "Trained words: 2310400, Loss: 7.9272\n",
      "空月滿花葉\n",
      "Trained words: 2313600, Loss: 7.9350\n",
      "無人無限此\n",
      "Trained words: 2316800, Loss: 7.8504\n",
      "何必任我長\n",
      "Trained words: 2320000, Loss: 7.8794\n",
      "不識不及者\n",
      "Trained words: 2323200, Loss: 7.6430\n",
      "無是自無心\n",
      "Trained words: 2326400, Loss: 7.8035\n",
      "一日不生生\n",
      "Trained words: 2329600, Loss: 8.3741\n",
      "誰謂別家翁\n",
      "Trained words: 2332800, Loss: 8.2715\n",
      "今無無處悲\n",
      "Trained words: 2336000, Loss: 8.2792\n",
      "夜眠風吹暖\n",
      "Trained words: 2339200, Loss: 7.6548\n",
      "天地不在人\n",
      "Trained words: 2342400, Loss: 7.8394\n",
      "歸人遠風歸\n",
      "Trained words: 2345600, Loss: 7.9494\n",
      "誰能知別意\n",
      "Trained words: 2348800, Loss: 7.6270\n",
      "一別離心遠\n",
      "Trained words: 2352000, Loss: 7.7013\n",
      "未人當此時\n",
      "Trained words: 2355200, Loss: 7.6448\n",
      "我在我道生\n",
      "Trained words: 2358400, Loss: 7.6517\n",
      "江海寒寒生\n",
      "Trained words: 2361600, Loss: 7.5475\n",
      "一來歲色枯\n",
      "Trained words: 2364800, Loss: 7.4315\n",
      "東樓有雲外\n",
      "Trained words: 2368000, Loss: 7.6112\n",
      "何知身如不\n",
      "Trained words: 2371200, Loss: 7.5401\n",
      "不知不與言\n",
      "Trained words: 2374400, Loss: 7.5489\n",
      "萬條已後時\n",
      "Trained words: 2377600, Loss: 7.6536\n",
      "春來複所思\n",
      "Trained words: 2380800, Loss: 7.4314\n",
      "自謂多心不\n",
      "Trained words: 2384000, Loss: 7.4119\n",
      "但憐此夜坐\n",
      "Trained words: 2387200, Loss: 7.4803\n",
      "自爾有不死\n",
      "Trained words: 2390400, Loss: 7.6250\n",
      "新作亦不能\n",
      "Trained words: 2393600, Loss: 7.7256\n",
      "無物複中年\n",
      "Trained words: 2396800, Loss: 7.7801\n",
      "相看來時起\n",
      "Trained words: 2400000, Loss: 8.2144\n",
      "天風多此樂\n",
      "Trained words: 2403200, Loss: 7.7334\n",
      "日夜紅蘭萼\n",
      "Trained words: 2406400, Loss: 7.7723\n",
      "一時相攜食\n",
      "Trained words: 2409600, Loss: 7.7079\n",
      "此來風天雨\n",
      "Trained words: 2412800, Loss: 7.7450\n",
      "猶坐未得衰\n",
      "Trained words: 2416000, Loss: 7.8558\n",
      "東南南十裏\n",
      "Trained words: 2419200, Loss: 7.6233\n",
      "南江江南雁\n",
      "Trained words: 2422400, Loss: 7.7261\n",
      "無事何同此\n",
      "Trained words: 2425600, Loss: 7.8375\n",
      "為物何如何\n",
      "Trained words: 2428800, Loss: 7.7559\n",
      "一年朝月上\n",
      "Trained words: 2432000, Loss: 7.6113\n",
      "風雪如絲葉\n",
      "Trained words: 2435200, Loss: 7.6994\n",
      "未去西時去\n",
      "Trained words: 2438400, Loss: 7.5995\n",
      "江行與長眼\n",
      "Trained words: 2441600, Loss: 7.7212\n",
      "不知一朝醉\n",
      "Trained words: 2444800, Loss: 7.7595\n",
      "獨望青雲天\n",
      "Trained words: 2448000, Loss: 7.7014\n",
      "今日與有人\n",
      "Trained words: 2451200, Loss: 7.7339\n",
      "長雲有人夢\n",
      "Trained words: 2454400, Loss: 7.8596\n",
      "此朝已歲年\n",
      "Trained words: 2457600, Loss: 7.9798\n",
      "豈謂我憂憂\n",
      "Trained words: 2460800, Loss: 7.8326\n",
      "誰自身勞不\n",
      "Trained words: 2464000, Loss: 7.7737\n",
      "中路多所久\n",
      "Trained words: 2467200, Loss: 7.9510\n",
      "一條何事不\n",
      "Trained words: 2470400, Loss: 7.8607\n",
      "況來為此國\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained words: 2473600, Loss: 7.8687\n",
      "清氣多餘病\n",
      "Trained words: 2476800, Loss: 8.0442\n",
      "人知是雲去\n",
      "Trained words: 2480000, Loss: 7.6341\n",
      "雲霞有青閣\n",
      "Trained words: 2483200, Loss: 7.5799\n",
      "東水何如何\n",
      "Trained words: 2486400, Loss: 7.9270\n",
      "寒月秋風吟\n",
      "Trained words: 2489600, Loss: 7.7145\n",
      "相逢歌遠聲\n",
      "Trained words: 2492800, Loss: 7.4779\n",
      "一曲水水中\n",
      "Trained words: 2496000, Loss: 7.5086\n",
      "此此清光光\n",
      "Trained words: 2499200, Loss: 7.4795\n",
      "不覺白頭生\n",
      "Trained words: 2502400, Loss: 7.5809\n",
      "應似身生老\n",
      "Trained words: 2505600, Loss: 7.4951\n",
      "心心已已身\n",
      "Trained words: 2508800, Loss: 7.6266\n",
      "高樓高望望\n",
      "Trained words: 2512000, Loss: 7.5134\n",
      "人有遠尋年\n",
      "Trained words: 2515200, Loss: 7.7128\n",
      "應不自相逢\n",
      "Trained words: 2518400, Loss: 7.6905\n",
      "君是一杯興\n",
      "Trained words: 2521600, Loss: 7.7966\n",
      "不喜春長春\n",
      "Trained words: 2524800, Loss: 7.6692\n",
      "何事不見長\n",
      "Trained words: 2528000, Loss: 7.7409\n",
      "為君喜子子\n",
      "Trained words: 2531200, Loss: 7.4706\n",
      "千丈何當來\n",
      "Trained words: 2534400, Loss: 7.6074\n",
      "清景複無心\n",
      "Trained words: 2537600, Loss: 7.8288\n",
      "雲外無無路\n",
      "Trained words: 2540800, Loss: 8.0624\n",
      "風人入一弦\n",
      "Trained words: 2544000, Loss: 8.0857\n",
      "獨問難家事\n",
      "Trained words: 2547200, Loss: 7.9108\n",
      "閑處伴君眠\n",
      "Trained words: 2550400, Loss: 7.7451\n",
      "日月臨秋色\n",
      "Trained words: 2553600, Loss: 7.6133\n",
      "遠心春深好\n",
      "Trained words: 2556800, Loss: 7.5155\n",
      "應為酒酒醒\n",
      "Trained words: 2560000, Loss: 7.4612\n",
      "水潭長雪樹\n",
      "Trained words: 2563200, Loss: 7.8935\n",
      "寒水不飛空\n",
      "Trained words: 2566400, Loss: 7.8941\n",
      "我心多所者\n",
      "Trained words: 2569600, Loss: 7.8728\n",
      "為君學舊年\n",
      "Trained words: 2572800, Loss: 7.9703\n",
      "山有白江花\n",
      "Trained words: 2576000, Loss: 8.0831\n",
      "孤窗高樹上\n",
      "Trained words: 2579200, Loss: 8.0330\n",
      "一燈自一枝\n",
      "Trained words: 2582400, Loss: 7.7628\n",
      "江南楚風流\n",
      "Trained words: 2585600, Loss: 7.5811\n",
      "不知非事在\n",
      "Trained words: 2588800, Loss: 7.6893\n",
      "此事幾歸去\n",
      "Trained words: 2592000, Loss: 7.7633\n",
      "我將一處還\n",
      "Trained words: 2595200, Loss: 7.5480\n",
      "青園古樹陰\n",
      "Trained words: 2598400, Loss: 7.4305\n",
      "為君不在君\n",
      "Trained words: 2601600, Loss: 7.5309\n",
      "風生何處事\n",
      "Trained words: 2604800, Loss: 7.7610\n",
      "雲高入鳳樓\n",
      "Trained words: 2608000, Loss: 7.7738\n",
      "天地上江秋\n",
      "Trained words: 2611200, Loss: 7.8728\n",
      "行聞白日盡\n",
      "Trained words: 2614400, Loss: 7.7358\n",
      "未見不逢時\n",
      "Trained words: 2617600, Loss: 7.8686\n",
      "豈能分自苦\n",
      "Trained words: 2620800, Loss: 7.8715\n",
      "白露開花香\n",
      "Trained words: 2624000, Loss: 7.7692\n",
      "高山向東州\n",
      "Trained words: 2627200, Loss: 7.6226\n",
      "時盡一成君\n",
      "Trained words: 2630400, Loss: 7.6292\n",
      "今年應見主\n",
      "Trained words: 2633600, Loss: 7.6572\n",
      "今朝日暮別\n",
      "Trained words: 2636800, Loss: 7.6339\n",
      "西天古北陽\n",
      "Trained words: 2640000, Loss: 8.1812\n",
      "水水雲寒水\n",
      "Trained words: 2643200, Loss: 7.8123\n",
      "心意何人苦\n",
      "Trained words: 2646400, Loss: 7.8285\n",
      "萬物豈殊心\n",
      "Trained words: 2649600, Loss: 7.5496\n",
      "獨有人歸夢\n",
      "Trained words: 2652800, Loss: 7.3355\n",
      "不敢思相識\n",
      "Trained words: 2656000, Loss: 7.5557\n",
      "新詩有夜日\n",
      "Trained words: 2659200, Loss: 7.6169\n",
      "不言能一道\n",
      "Trained words: 2662400, Loss: 7.4399\n",
      "一樹猶不晚\n",
      "Trained words: 2665600, Loss: 7.3475\n",
      "春水水不能\n",
      "Trained words: 2668800, Loss: 7.8311\n",
      "高陽滿野人\n",
      "Trained words: 2672000, Loss: 7.5280\n",
      "無得盡為名\n",
      "Trained words: 2675200, Loss: 7.4886\n",
      "春年逐人去\n",
      "Trained words: 2678400, Loss: 7.6611\n",
      "自見山相路\n",
      "Trained words: 2681600, Loss: 7.9148\n",
      "自無生不得\n",
      "Trained words: 2684800, Loss: 8.1101\n",
      "誰知入天人\n",
      "Trained words: 2688000, Loss: 8.1199\n",
      "無無有主人\n",
      "Trained words: 2691200, Loss: 8.0493\n",
      "一人不得日\n",
      "Trained words: 2694400, Loss: 7.9259\n",
      "中家皆萬者\n",
      "Trained words: 2697600, Loss: 8.1332\n",
      "閑來更見月\n",
      "Trained words: 2700800, Loss: 8.0834\n",
      "清吹滿夜月\n",
      "Trained words: 2704000, Loss: 7.9481\n",
      "我得似幽客\n",
      "Trained words: 2707200, Loss: 7.9906\n",
      "古日無如力\n",
      "Trained words: 2710400, Loss: 7.7940\n",
      "孤舟不所尋\n",
      "Trained words: 2713600, Loss: 8.1614\n",
      "歸鳥落煙光\n",
      "Trained words: 2716800, Loss: 7.7906\n",
      "不及寒山靜\n",
      "Trained words: 2720000, Loss: 7.7026\n",
      "南溟一萬里\n",
      "Trained words: 2723200, Loss: 7.4410\n",
      "高樓有所陽\n",
      "Trained words: 2726400, Loss: 7.5098\n",
      "清風草樹開\n",
      "Trained words: 2729600, Loss: 7.6040\n",
      "一片如花盡\n",
      "Trained words: 2732800, Loss: 7.6734\n",
      "不敢知君遇\n",
      "Trained words: 2736000, Loss: 7.5141\n",
      "莫歸雲間外\n",
      "Trained words: 2739200, Loss: 7.8177\n",
      "春上雁啼斷\n",
      "Trained words: 2742400, Loss: 7.8002\n",
      "山上無塵間\n",
      "Trained words: 2745600, Loss: 7.9324\n",
      "遠山見遠程\n",
      "Trained words: 2748800, Loss: 7.6687\n",
      "秋年是君時\n",
      "Trained words: 2752000, Loss: 7.7772\n",
      "自身無遠窮\n",
      "Trained words: 2755200, Loss: 7.6794\n",
      "行馬問何同\n",
      "Trained words: 2758400, Loss: 7.6812\n",
      "何因得得生\n",
      "Trained words: 2761600, Loss: 7.8833\n",
      "春思思悠悠\n",
      "Trained words: 2764800, Loss: 7.8926\n",
      "我笑一枝花\n",
      "Trained words: 2768000, Loss: 7.8031\n",
      "此意無不厭\n",
      "Trained words: 2771200, Loss: 7.3279\n",
      "白髮生衣輕\n",
      "Trained words: 2774400, Loss: 7.7013\n",
      "無由有心知\n",
      "Trained words: 2777600, Loss: 7.9798\n",
      "長應別離別\n",
      "Trained words: 2780800, Loss: 7.6705\n",
      "一家別此餘\n",
      "Trained words: 2784000, Loss: 7.5897\n",
      "夜晚風霜雨\n",
      "Trained words: 2787200, Loss: 7.8641\n",
      "白人歸客恨\n",
      "Trained words: 2790400, Loss: 7.7216\n",
      "不覺長安不\n",
      "Trained words: 2793600, Loss: 7.6329\n",
      "一花亦可然\n",
      "Trained words: 2796800, Loss: 7.6964\n",
      "一里白無生\n",
      "Trained words: 2800000, Loss: 7.7181\n",
      "終將不成春\n",
      "Trained words: 2803200, Loss: 7.7843\n",
      "人家一夜聞\n",
      "Trained words: 2806400, Loss: 7.6453\n",
      "莫嫌一淚杯\n",
      "Trained words: 2809600, Loss: 7.7322\n",
      "何處在江湖\n",
      "Trained words: 2812800, Loss: 7.7202\n",
      "風吹月色新\n",
      "Trained words: 2816000, Loss: 7.9155\n",
      "風雨多山月\n",
      "Trained words: 2819200, Loss: 7.9512\n",
      "有古石蘿通\n",
      "Trained words: 2822400, Loss: 7.7974\n",
      "應有江中去\n",
      "Trained words: 2825600, Loss: 7.7675\n",
      "花開白柳色\n",
      "Trained words: 2828800, Loss: 7.7752\n",
      "東川隔白衣\n",
      "Trained words: 2832000, Loss: 7.8227\n",
      "不待歸雲起\n",
      "Trained words: 2835200, Loss: 7.7451\n",
      "千里在南樓\n",
      "Trained words: 2838400, Loss: 7.9696\n",
      "一時知一片\n",
      "Trained words: 2841600, Loss: 7.8123\n",
      "時人自往日\n",
      "Trained words: 2844800, Loss: 7.9704\n",
      "江寒月雲時\n",
      "Trained words: 2848000, Loss: 7.8947\n",
      "自是有清心\n",
      "Trained words: 2851200, Loss: 7.8581\n",
      "天臺望杳雲\n",
      "Trained words: 2854400, Loss: 7.8860\n",
      "天風雪地秋\n",
      "Trained words: 2857600, Loss: 7.9303\n",
      "花上正相期\n",
      "Trained words: 2860800, Loss: 8.4343\n",
      "誰語更堪同\n",
      "Trained words: 2864000, Loss: 8.3317\n",
      "何時是帝孫\n",
      "Trained words: 2867200, Loss: 7.9679\n",
      "有君思不得\n",
      "Trained words: 2870400, Loss: 7.7506\n",
      "寒風日半中\n",
      "Trained words: 2873600, Loss: 7.7347\n",
      "天生清泠清\n",
      "Trained words: 2876800, Loss: 7.9614\n",
      "江海自歸人\n",
      "Trained words: 2880000, Loss: 7.8131\n",
      "青霄共可遊\n",
      "Trained words: 2883200, Loss: 7.7395\n",
      "月出山河去\n",
      "Trained words: 2886400, Loss: 7.6912\n",
      "青雲自不歸\n",
      "Trained words: 2889600, Loss: 7.6945\n",
      "如何問古林\n",
      "Trained words: 2892800, Loss: 7.6270\n",
      "山巒重城北\n",
      "Trained words: 2896000, Loss: 7.8210\n",
      "為人如何是\n",
      "Trained words: 2899200, Loss: 7.7372\n",
      "不識誰逢住\n",
      "Trained words: 2902400, Loss: 7.7505\n",
      "寒光碧天煙\n",
      "Trained words: 2905600, Loss: 7.6466\n",
      "日明看月照\n",
      "Trained words: 2908800, Loss: 7.6168\n",
      "長人一遠意\n",
      "Trained words: 2912000, Loss: 7.7019\n",
      "寒月日中林\n",
      "Trained words: 2915200, Loss: 7.6267\n",
      "一徑長心生\n",
      "Trained words: 2918400, Loss: 7.7441\n",
      "不及誰人知\n",
      "Trained words: 2921600, Loss: 7.8570\n",
      "松影清清清\n",
      "Trained words: 2924800, Loss: 7.7249\n",
      "人無山上處\n",
      "Trained words: 2928000, Loss: 7.8174\n",
      "遠遊多所適\n",
      "Trained words: 2931200, Loss: 7.8187\n",
      "何年好故人\n",
      "Trained words: 2934400, Loss: 7.8295\n",
      "江流萬萬里\n",
      "Trained words: 2937600, Loss: 7.6932\n",
      "江浦繞風水\n",
      "Trained words: 2940800, Loss: 7.6725\n",
      "人外萬里難\n",
      "Trained words: 2944000, Loss: 7.6628\n",
      "不問他人別\n",
      "Trained words: 2947200, Loss: 7.6465\n",
      "相聞西門客\n",
      "Trained words: 2950400, Loss: 7.6409\n",
      "無山有遠年\n",
      "Trained words: 2953600, Loss: 7.6638\n",
      "我來誰共處\n",
      "Trained words: 2956800, Loss: 7.5830\n",
      "雲煙在綠芳\n",
      "Trained words: 2960000, Loss: 7.7031\n",
      "東窗起後來\n",
      "Trained words: 2963200, Loss: 7.5733\n",
      "只寄白雲生\n",
      "Trained words: 2966400, Loss: 8.1399\n",
      "時此自無塵\n",
      "Trained words: 2969600, Loss: 7.9201\n",
      "清吟不可在\n",
      "Trained words: 2972800, Loss: 7.7111\n",
      "莫為天漢心\n",
      "Trained words: 2976000, Loss: 7.7875\n",
      "如君出諸侯\n",
      "Trained words: 2979200, Loss: 7.9732\n",
      "江塘去流水\n",
      "Trained words: 2982400, Loss: 7.9334\n",
      "何人一道意\n",
      "Trained words: 2985600, Loss: 7.7760\n",
      "何用問長知\n",
      "Trained words: 2988800, Loss: 7.9408\n",
      "天道舊春山\n",
      "Trained words: 2992000, Loss: 7.8033\n",
      "長安識此期\n",
      "Trained words: 2995200, Loss: 7.8662\n",
      "自見風華景\n"
     ]
    }
   ],
   "source": [
    "parameters = model('./data/poem5.txt', word2idx_map, embeddings, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Poem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_poem_sentense(parameters, idx2word_map, embeddings, inputs=None, length=7, criteria='beam_random', bwidth=100):\n",
    "    '''\n",
    "    Arguments:\n",
    "    parameters -- dictionary\n",
    "    inputs -- tuple\n",
    "    idx2word_map -- list\n",
    "    embeddings -- numpy array\n",
    "    length -- int\n",
    "    \n",
    "    Returns:\n",
    "    sen -- string\n",
    "    '''\n",
    "    n_x, n_y = embeddings.shape\n",
    "    n_a = parameters['bf'].shape[0]\n",
    "    if inputs is not None:\n",
    "        x, at, ct = inputs\n",
    "    else:\n",
    "        x = np.zeros((n_x, 1))\n",
    "        at = np.zeros((n_a, 1))\n",
    "        ct = np.zeros((n_a, 1))\n",
    "    \n",
    "    sen = ''\n",
    "    for t in range(length):\n",
    "        at, ct, y_pred_t, _ = cell_forward(x, at, ct, parameters)\n",
    "        if criteria == 'random':\n",
    "            idx = np.random.choice(n_y, p=y_pred_t.ravel())\n",
    "        elif criteria == 'max':\n",
    "            idx = np.argmax(y_pred_t)\n",
    "        elif criteria == 'beam_random':\n",
    "            sample = heapq.nlargest(bwidth, enumerate(y_pred_t.ravel()), key=lambda x: x[1])\n",
    "            prob = np.array([x[1] for x in sample])\n",
    "            sample_idx = [x[0] for x in sample]\n",
    "            idx = np.random.choice(sample_idx, p=prob / sum(prob))\n",
    "        elif criteria == 'beam_search':\n",
    "            pass\n",
    "            \n",
    "        x = embeddings[:, [idx]]\n",
    "        sen += idx2word_map[idx]\n",
    "        \n",
    "    return sen, at, ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "香林在此山\n",
      "花菊醒聞笑\n",
      "熟酒食啼金\n",
      "亂食盈蟬草\n"
     ]
    }
   ],
   "source": [
    "n_x, n_y = embeddings.shape\n",
    "n_a = 64\n",
    "\n",
    "x = np.zeros((n_x, 1))\n",
    "a0 = np.zeros((n_a, 1))\n",
    "c0 = np.zeros((n_a, 1))\n",
    "\n",
    "for _ in range(4):\n",
    "    sen, a0, c0 = generate_poem_sentense(parameters, idx2word_map, embeddings, (x, a0, c0),\n",
    "                                         length=5)\n",
    "    print(sen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_model_to_file(file_name, data):\n",
    "    '''\n",
    "    Arguments:\n",
    "    file_name -- string\n",
    "    data -- numpy array\n",
    "    '''\n",
    "    path = 'output/'\n",
    "    if not os.path.isdir(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "    data_of_list = {}\n",
    "    for key, val in data.items():\n",
    "        data_of_list[key] = val.tolist()\n",
    "        \n",
    "    with open(path + file_name, \"w\") as f:\n",
    "        f.write(json.dumps(data_of_list, indent=4))\n",
    "        \n",
    "def load_model_from_file(file_name):\n",
    "    '''\n",
    "    Arguments:\n",
    "    file_name -- the json file name saving results.\n",
    "\n",
    "    Returns:\n",
    "    data -- numpy array\n",
    "    '''    \n",
    "    with open(file_name, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    for key in data.keys():\n",
    "        data[key] = np.array(data[key])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parameters = load_model_from_file('weights/lstm_weights_5.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
